{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff4b397-89c5-4a59-bebd-eb106fa6072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk import ngrams\n",
    "import nltk\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import unicodedata\n",
    "from dateutil import parser\n",
    "import random\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61cd0c-6c03-44e7-94e1-f69e7609a2e7",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e1d531-3112-494a-a4b1-b2169e90479a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted list numbers from 100_Day11.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 104_Day11.txt: \n",
      "['1.\\t', '2.\\t', '3.\\t', '4.\\t', '5.\\t', '6.\\t', '7.\\t', '8.\\t', '9.\\t']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 125_Day1.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 125_Day14.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 135_Day11.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 158_Day3.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 158_Day7.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 158_Day8.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 164_Day11.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 165_Day14.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 165_Day8.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 169_Day10.txt: \n",
      "['1.\\t', '2.\\t', '3.\\t', '4.\\t', '5.\\t', '6.\\t', '7.\\t', '8.\\t', '9.\\t', '10.\\t', '11.\\t']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 173_Day2.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 188_Day8.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 191_Day13.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 191_Day4.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 197_Day4.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 199_Day5.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 200_Day7.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 201_Day8.txt: \n",
      "['1.', '2.', '3.', '4.', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 208_Day3.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 211_Day8.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 213_Day4.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ', '11. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 214_Day12.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 223_Day14.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 223_Day8.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 224_Day14.txt: \n",
      "[]\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 224_Day3.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 225_Day2.txt: \n",
      "['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 228_Day1.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 229_Day7.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5.', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 230_Day11.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 240_Day10.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 245_Day1.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 245_Day8.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 250_Day5.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 250_Day9.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 257_Day12.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 257_Day4.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 274_Day2.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 280_Day13.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 285_Day4.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 285_Day7.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 290_Day4.txt: \n",
      "['1)_ ', '2)_ ', '3)_ ', '4)_ ', '5)_', '6)_ ', '7)_', '8)_ ', '9)_ ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 291_Day1.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10.']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 304_Day9.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 311_Day5.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 311_Day6.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 331_Day10.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 336_Day12.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 337_Day3.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 343_Day13.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 344_Day13.txt: \n",
      "['1.', '2.', '3.', '4.', '5.', '6.', '7.']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 350_Day7.txt: \n",
      "['1.\\t', '\\t2.\\t', '\\t3.\\t', '\\t4.\\t', '\\t5.\\t', '\\t6.\\t', '\\t7.\\t', '\\t8.\\t', '\\t9.\\t', '\\t10.\\t']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 356_Day9.txt: \n",
      "['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 360_Day7.txt: \n",
      "['2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 360_Day9.txt: \n",
      "['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 363_Day13.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 366_Day4.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '10.']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 367_Day1.txt: \n",
      "['1)', '2)', '3)', '4)', '5)', '6)', '7)', '8))', '9)', '10)']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 367_Day14.txt: \n",
      "['1)', '2)', '3)', '4)', '5)', '6)', '7)', '8)', '9)', '10)']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 369_Day14.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 369_Day9.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 370_Day6.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 373_Day5.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 378_Day4.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 380_Day12.txt: \n",
      "['1.\\t', '2.\\t', '3.\\t', '4.\\t', '5.\\t', '6.\\t', '7.\\t', '8.\\t', '9.\\t', '10.\\t']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 381_Day1.txt: \n",
      "[]\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 381_Day6.txt: \n",
      "[]\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 390_Day9.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 393_Day1.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10.']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 393_Day2.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 402_Day10.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7.', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 404_Day11.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ', '11. ', '12. ', '13. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 405_Day1.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 407_Day8.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 410_Day10.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 410_Day3.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 415_Day3.txt: \n",
      "['1) ', '2) ', '3) ', '4) ', '5) ', '6) ', '7) ', '8) ', '9) ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 419_Day13.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 419_Day5.txt: \n",
      "[]\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 421_Day5.txt: \n",
      "['1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 430_Day10.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 433_Day14.txt: \n",
      "['1. ', '2.\\t', '3.\\t', '4.\\t', '5.\\t', '6.\\t', '7.\\t', '8.\\t', '9.\\t', '10.\\t']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 436_Day13.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 441_Day11.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 453_Day10.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 461_Day9.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 462_Day2.txt: \n",
      "['1. ', '2. ', '3.', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ', '11. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 465_Day14.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 465_Day2.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 484_Day8.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 491_Day6.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 492_Day14.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 531_Day5.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 577_Day12.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 671_Day3.txt: \n",
      "[' 1.', ' 2.', ' 3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 689_Day12.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 956_Day5.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 961_Day4.txt: \n",
      "['1. ', '2. ', '3. ', '4. ', '5. ', '6. ', '7. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day1.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day10.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day11.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day12.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day13.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day14.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day2.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day3.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day4.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day5.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day6.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day7.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ', '11. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day8.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ', '9. ', '10. ']\n",
      "--------------------------------------------------\n",
      "Extracted list numbers from 22i0560_KhadijaHaider_Day9.txt: \n",
      "['2. ', '3. ', '4. ', '5. ', '6. ', '7. ', '8. ']\n",
      "--------------------------------------------------\n",
      "Corpus and test dataset processing complete.\n"
     ]
    }
   ],
   "source": [
    "corpus_folder = r\"C:\\Users\\User\\Downloads\\NLP\\BPE_dataset\\dataset\"\n",
    "test_folder = r\"C:\\Users\\User\\Downloads\\NLP\\BPE_test\"\n",
    "\n",
    "list_numbering_pattern = r'^\\s*\\(?\\d+[\\.\\)\\-_\\*]+\\s*'  \n",
    "punctuation_pattern = r'[^\\w\\s:.,]' \n",
    "\n",
    "def remove_list_numbering(text):\n",
    "    \"\"\" Remove list numbering and bullets while preserving content. \"\"\"\n",
    "    cleaned_lines = []\n",
    "    extracted_numbers = []\n",
    "    \n",
    "    for line in text.split(\"\\n\"):\n",
    "        match = re.match(list_numbering_pattern, line)\n",
    "        if match:\n",
    "            extracted_numbers.append(match.group()) \n",
    "            line = re.sub(list_numbering_pattern, '', line)  \n",
    "        \n",
    "        cleaned_lines.append(line.strip())\n",
    "    \n",
    "    return extracted_numbers, \" \".join(cleaned_lines)\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\" Normalize accented characters and remove unnecessary punctuation. \"\"\"\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c))\n",
    "    text = re.sub(punctuation_pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def process_text_files(folder_path):\n",
    "    \"\"\" Process all text files in a given folder and return cleaned corpus. \"\"\"\n",
    "    corpus = \"\"\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read()\n",
    "            except UnicodeDecodeError:\n",
    "                with open(file_path, 'r', encoding='latin-1', errors='ignore') as f:\n",
    "                    text = f.read()\n",
    "            \n",
    "            extracted_numbers, cleaned_text = remove_list_numbering(text)\n",
    "            cleaned_text = normalize_text(cleaned_text)\n",
    "            \n",
    "            print(f\"Extracted list numbers from {filename}: \\n{extracted_numbers}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            corpus += cleaned_text + \" \"\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "# Process both datasets\n",
    "corpus = process_text_files(corpus_folder).lower()\n",
    "corpus = corpus.replace(\",\", \"\").replace(\".\", \"\")\n",
    "corpus = re.sub(r\"\\s+\", \" \", corpus).strip() \n",
    "\n",
    "test = process_text_files(test_folder)\n",
    "test = test.replace(\",\", \"\").replace(\".\", \"\")\n",
    "test = re.sub(r\"\\s+\", \" \", test).strip() \n",
    "\n",
    "print(\"Corpus and test dataset processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba780b8-eb99-4028-bb03-3cba4741a017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subha 5 bjhey uthna perha trip thaa jaldi jaldi ready hua aur 0540 ghar saay nikal gaay 0615 bus chal perhee joo kaay first time thaa kaay trip time saay chala nust kaay 3 larkay thy unsaay batain kee phir bluetooth trip coordinator kaay pass thaa tou humm shoor daltay rahay kaay song change krr dain phir murree mein nashtay kaay leya uthay phir usskay baad bluetooth humain mil gaya mein tou soogaya phir hum jaga prr phouch gaay udhar 3 peaks theen 2 perr char gaay aik prr sahi ghalat raastay saay gaay thy full steep thaa mujhey tou laga mein gaya peak prr pohouch gaya phir picks leen phir slow wala group bhee aa gaya thaa unn kaay sath dubara picks leen wapsi prr jeep mein bohot rash thaa phir dinner keya ghar gaay aur soogaau subah 8 bjy utha fresh hua nashta kiya aur university k liye tyaar honay laga 9 bjy apne bike pe university k liye nikal gaya aj friday ha aur aj mere sirf 2 classes huti hain university ponch k classes li pehla lecture nlp ka tha jis me bhut maza aata ha q k hm'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956ce78d-05b5-4870-964d-c133d744433e",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f5e6ed-3c78-4797-801b-d258b6672462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16238"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(word_tokenize(corpus))\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7485ed59-572c-4b88-ba1a-1009b9e5f07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16238"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "for i in nltk.sent_tokenize(corpus):\n",
    "    tokens.extend(list(word_tokenize(i)))\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa710f8-021f-4cdc-989f-8e97bd011a14",
   "metadata": {},
   "source": [
    "# Training n-gram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c39ae3ed-5b92-456c-b78f-9ac15c2d3e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16237"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = list(ngrams(tokens, 2))\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "lenbigram = 0\n",
    "for gram in bigrams:\n",
    "    # print(gram)\n",
    "    lenbigram+=1\n",
    "lenbigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5764a396-ec2a-4041-a1fe-dbe1b5f5cf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('ke', 'baad'): 63,\n",
       "         ('aur', 'phir'): 55,\n",
       "         ('kiya', 'aur'): 49,\n",
       "         ('ki', 'namaz'): 49,\n",
       "         ('k', 'baad'): 46,\n",
       "         ('chala', 'gaya'): 45,\n",
       "         ('ki', 'aur'): 44,\n",
       "         ('ke', 'liye'): 44,\n",
       "         ('or', 'phir'): 42,\n",
       "         ('khana', 'khaya'): 39,\n",
       "         ('k', 'liye'): 32,\n",
       "         ('namaz', 'parhi'): 31,\n",
       "         ('k', 'sath'): 29,\n",
       "         ('uske', 'baad'): 28,\n",
       "         ('nashta', 'kiya'): 27,\n",
       "         ('raat', 'ko'): 26,\n",
       "         ('raha', 'tha'): 26,\n",
       "         ('ke', 'sath'): 26,\n",
       "         ('thodi', 'der'): 23,\n",
       "         ('mein', 'ne'): 21,\n",
       "         ('ki', 'class'): 21,\n",
       "         ('so', 'gaya'): 20,\n",
       "         ('ka', 'kaam'): 20,\n",
       "         ('ke', 'saath'): 20,\n",
       "         ('tha', 'to'): 20,\n",
       "         ('ka', 'khana'): 19,\n",
       "         ('kiya', 'phir'): 18,\n",
       "         ('ho', 'gaya'): 18,\n",
       "         ('utha', 'aur'): 18,\n",
       "         ('ka', 'time'): 17,\n",
       "         ('university', 'ka'): 17,\n",
       "         ('ghar', 'walon'): 17,\n",
       "         ('kay', 'baad'): 17,\n",
       "         ('ki', 'or'): 16,\n",
       "         ('university', 'ke'): 16,\n",
       "         ('hum', 'ne'): 16,\n",
       "         ('khaya', 'aur'): 16,\n",
       "         ('ki', 'phir'): 16,\n",
       "         ('namaz', 'ada'): 16,\n",
       "         ('baje', 'tak'): 16,\n",
       "         ('uth', 'kar'): 15,\n",
       "         ('kia', 'aur'): 15,\n",
       "         ('ada', 'ki'): 15,\n",
       "         ('mei', 'nei'): 15,\n",
       "         ('parhi', 'aur'): 14,\n",
       "         ('ho', 'kar'): 14,\n",
       "         ('ka', 'din'): 14,\n",
       "         ('gaya', 'aur'): 13,\n",
       "         ('gayi', 'aur'): 13,\n",
       "         ('kaam', 'kiya'): 13,\n",
       "         ('attend', 'ki'): 13,\n",
       "         ('aur', 'kuch'): 13,\n",
       "         ('raat', 'ka'): 13,\n",
       "         ('shaam', 'ko'): 13,\n",
       "         ('thodi', 'dair'): 13,\n",
       "         ('phir', 'hum'): 12,\n",
       "         ('nikal', 'gaya'): 12,\n",
       "         ('thori', 'der'): 12,\n",
       "         ('us', 'k'): 12,\n",
       "         ('thori', 'dair'): 12,\n",
       "         ('le', 'kar'): 12,\n",
       "         ('uskay', 'baad'): 12,\n",
       "         ('baad', 'mai'): 12,\n",
       "         ('gaya', 'aj'): 11,\n",
       "         ('kiya', 'or'): 11,\n",
       "         ('kia', 'or'): 11,\n",
       "         ('10', 'bajay'): 11,\n",
       "         ('baatein', 'ki'): 11,\n",
       "         ('chala', 'gya'): 11,\n",
       "         ('tha', 'isliye'): 11,\n",
       "         ('phir', 'ghar'): 11,\n",
       "         ('class', 'mein'): 11,\n",
       "         ('baje', 'utha'): 11,\n",
       "         ('rahi', 'thi'): 11,\n",
       "         ('doston', 'ke'): 11,\n",
       "         ('liye', 'nikal'): 10,\n",
       "         ('classes', 'li'): 10,\n",
       "         ('bajay', 'utha'): 10,\n",
       "         ('li', 'aur'): 10,\n",
       "         ('ghar', 'aa'): 10,\n",
       "         ('se', 'free'): 10,\n",
       "         ('dekha', 'aur'): 10,\n",
       "         ('quiz', 'ki'): 10,\n",
       "         ('baat', 'ki'): 10,\n",
       "         ('phone', 'use'): 10,\n",
       "         ('nashta', 'kia'): 10,\n",
       "         ('aaj', 'subah'): 10,\n",
       "         ('gaya', 'phir'): 9,\n",
       "         ('university', 'k'): 9,\n",
       "         ('jana', 'tha'): 9,\n",
       "         ('isha', 'ki'): 9,\n",
       "         ('aaj', 'mein'): 9,\n",
       "         ('doston', 'se'): 9,\n",
       "         ('aur', 'uske'): 9,\n",
       "         ('chali', 'gayi'): 9,\n",
       "         ('assignment', 'ki'): 9,\n",
       "         ('din', 'ki'): 9,\n",
       "         ('thora', 'sa'): 9,\n",
       "         ('bajay', 'tak'): 9,\n",
       "         ('kiye', 'aur'): 9,\n",
       "         ('9', 'bajay'): 9,\n",
       "         ('fajr', 'ki'): 9,\n",
       "         ('utha', 'or'): 9,\n",
       "         ('wapis', 'aa'): 9,\n",
       "         ('mobile', 'use'): 9,\n",
       "         ('ka', 'plan'): 9,\n",
       "         ('class', 'li'): 9,\n",
       "         ('phir', 'main'): 9,\n",
       "         ('kai', 'baad'): 9,\n",
       "         ('ki', 'thi'): 9,\n",
       "         ('ham', 'ne'): 9,\n",
       "         ('nahi', 'tha'): 9,\n",
       "         ('wajah', 'se'): 9,\n",
       "         ('is', 'liye'): 9,\n",
       "         ('jaldi', 'jaldi'): 8,\n",
       "         ('aur', 'university'): 8,\n",
       "         ('nlp', 'ka'): 8,\n",
       "         ('university', 'se'): 8,\n",
       "         ('jummah', 'ki'): 8,\n",
       "         ('gup', 'shup'): 8,\n",
       "         ('k', 'bad'): 8,\n",
       "         ('gaya', 'aaj'): 8,\n",
       "         ('uske', 'bd'): 8,\n",
       "         ('bd', 'mein'): 8,\n",
       "         ('so', 'gayi'): 8,\n",
       "         ('class', 'thi'): 8,\n",
       "         ('thi', 'to'): 8,\n",
       "         ('parhi', 'or'): 8,\n",
       "         ('ki', 'tyari'): 8,\n",
       "         ('tyari', 'ki'): 8,\n",
       "         ('khana', 'khanay'): 8,\n",
       "         ('so', 'gai'): 8,\n",
       "         ('ho', 'raha'): 8,\n",
       "         ('par', 'kaam'): 8,\n",
       "         ('use', 'kia'): 8,\n",
       "         ('6', 'bajay'): 8,\n",
       "         ('doston', 'k'): 8,\n",
       "         ('mil', 'kar'): 8,\n",
       "         ('aaj', 'ka'): 8,\n",
       "         ('11', 'bajay'): 8,\n",
       "         ('tha', 'lekin'): 8,\n",
       "         ('bus', 'mein'): 8,\n",
       "         ('kia', 'phir'): 8,\n",
       "         ('kar', 'diya'): 8,\n",
       "         ('mai', 'na'): 8,\n",
       "         ('kar', 'nashta'): 7,\n",
       "         ('sham', 'ko'): 7,\n",
       "         ('ghar', 'wapis'): 7,\n",
       "         ('shuru', 'ki'): 7,\n",
       "         ('pohanch', 'kar'): 7,\n",
       "         ('baad', 'hum'): 7,\n",
       "         ('ki', 'classes'): 7,\n",
       "         ('maghrib', 'ki'): 7,\n",
       "         ('uthi', 'aur'): 7,\n",
       "         ('sab', 'se'): 7,\n",
       "         ('ka', 'quiz'): 7,\n",
       "         ('wahan', 'se'): 7,\n",
       "         ('subah', '10'): 7,\n",
       "         ('so', 'gya'): 7,\n",
       "         ('attend', 'kiya'): 7,\n",
       "         ('ghar', 'a'): 7,\n",
       "         ('phir', 'kuch'): 7,\n",
       "         ('tha', 'tou'): 7,\n",
       "         ('ka', 'baad'): 7,\n",
       "         ('gaya', 'or'): 7,\n",
       "         ('aya', 'aur'): 7,\n",
       "         ('walon', 'ke'): 7,\n",
       "         ('social', 'media'): 7,\n",
       "         ('pehli', 'class'): 7,\n",
       "         ('aur', 'nashta'): 7,\n",
       "         ('ky', 'sat'): 7,\n",
       "         ('khaya', 'phir'): 7,\n",
       "         ('karne', 'ka'): 7,\n",
       "         ('phir', 'mein'): 7,\n",
       "         ('chalay', 'gaye'): 7,\n",
       "         ('baad', 'mainay'): 7,\n",
       "         ('se', 'pehlay'): 7,\n",
       "         ('baad', 'main'): 7,\n",
       "         ('lag', 'raha'): 7,\n",
       "         ('karne', 'ke'): 7,\n",
       "         ('kuch', 'der'): 7,\n",
       "         ('thi', 'tou'): 7,\n",
       "         ('baad', 'mei'): 7,\n",
       "         ('se', 'pehle'): 6,\n",
       "         ('rest', 'kiya'): 6,\n",
       "         ('ko', 'ghar'): 6,\n",
       "         ('wapis', 'aya'): 6,\n",
       "         ('6', 'baje'): 6,\n",
       "         ('se', 'farigh'): 6,\n",
       "         ('8', 'bajay'): 6,\n",
       "         ('nlp', 'ki'): 6,\n",
       "         ('aa', 'k'): 6,\n",
       "         ('aur', 'sath'): 6,\n",
       "         ('tha', 'phir'): 6,\n",
       "         ('pdc', 'ki'): 6,\n",
       "         ('chai', 'pi'): 6,\n",
       "         ('kaam', 'shuru'): 6,\n",
       "         ('kaam', 'bhi'): 6,\n",
       "         ('phir', 'se'): 6,\n",
       "         ('mein', 'beth'): 6,\n",
       "         ('ki', 'assignment'): 6,\n",
       "         ('mama', 'ne'): 6,\n",
       "         ('7', 'baje'): 6,\n",
       "         ('jaldi', 'se'): 6,\n",
       "         ('ke', 'liya'): 6,\n",
       "         ('ki', 'koshish'): 6,\n",
       "         ('baad', 'mein'): 6,\n",
       "         ('phir', 'so'): 6,\n",
       "         ('aram', 'kiya'): 6,\n",
       "         ('use', 'kiya'): 6,\n",
       "         ('tak', 'classes'): 6,\n",
       "         ('ka', 'sath'): 6,\n",
       "         ('baad', 'thodi'): 6,\n",
       "         ('lunch', 'kiya'): 6,\n",
       "         ('media', 'scroll'): 6,\n",
       "         ('fresh', 'feel'): 6,\n",
       "         ('phir', 'university'): 6,\n",
       "         ('ghar', 'wapas'): 6,\n",
       "         ('gaya', 'ghar'): 6,\n",
       "         ('phir', 'nashta'): 6,\n",
       "         ('baad', 'ma'): 6,\n",
       "         ('ki', 'wajah'): 6,\n",
       "         ('class', 'attend'): 6,\n",
       "         ('baad', 'namaz'): 6,\n",
       "         ('main', 'ny'): 6,\n",
       "         ('ky', 'bad'): 6,\n",
       "         ('hai', 'aur'): 6,\n",
       "         ('bus', 'stop'): 6,\n",
       "         ('thi', 'aur'): 6,\n",
       "         ('phir', 'me'): 6,\n",
       "         ('thi', 'toh'): 6,\n",
       "         ('or', 'university'): 6,\n",
       "         ('tha', 'is'): 6,\n",
       "         ('thoda', 'relax'): 6,\n",
       "         ('aur', 'kaam'): 6,\n",
       "         ('dinner', 'kiya'): 6,\n",
       "         ('aram', 'se'): 6,\n",
       "         ('call', 'ki'): 6,\n",
       "         ('nashta', 'karne'): 6,\n",
       "         ('socha', 'ke'): 6,\n",
       "         ('adaa', 'ki'): 6,\n",
       "         ('10', 'baje'): 6,\n",
       "         ('kei', 'baad'): 6,\n",
       "         ('phir', 'uske'): 6,\n",
       "         ('hota', 'hai'): 6,\n",
       "         ('kaam', 'kia'): 6,\n",
       "         ('thori', 'si'): 6,\n",
       "         ('fresh', 'hua'): 5,\n",
       "         ('2', 'classes'): 5,\n",
       "         ('ghar', 'k'): 5,\n",
       "         ('ki', 'tyaari'): 5,\n",
       "         ('tyaari', 'ki'): 5,\n",
       "         ('namaz', 'k'): 5,\n",
       "         ('aj', 'meri'): 5,\n",
       "         ('tha', 'aur'): 5,\n",
       "         ('gaye', 'aur'): 5,\n",
       "         ('waja', 'se'): 5,\n",
       "         ('ghar', 'pohanch'): 5,\n",
       "         ('islamabad', 'k'): 5,\n",
       "         ('tha', 'tu'): 5,\n",
       "         ('chale', 'gaye'): 5,\n",
       "         ('scroll', 'kiya'): 5,\n",
       "         ('mai', 'subah'): 5,\n",
       "         ('se', 'mila'): 5,\n",
       "         ('ghar', 'aaya'): 5,\n",
       "         ('asar', 'ki'): 5,\n",
       "         ('waqt', 'guzara'): 5,\n",
       "         ('12', 'bajay'): 5,\n",
       "         ('aur', 'tyar'): 5,\n",
       "         ('ke', 'lya'): 5,\n",
       "         ('gayi', 'aaj'): 5,\n",
       "         ('dip', 'ka'): 5,\n",
       "         ('beth', 'kr'): 5,\n",
       "         ('ke', 'bd'): 5,\n",
       "         ('ne', 'khana'): 5,\n",
       "         ('tv', 'dekha'): 5,\n",
       "         ('aur', 'us'): 5,\n",
       "         ('ki', 'tiyari'): 5,\n",
       "         ('kuch', 'time'): 5,\n",
       "         ('cnet', 'ki'): 5,\n",
       "         ('namaz', 'parh'): 5,\n",
       "         ('tha', 'or'): 5,\n",
       "         ('aa', 'kr'): 5,\n",
       "         ('late', 'ho'): 5,\n",
       "         ('parh', 'ke'): 5,\n",
       "         ('neend', 'aa'): 5,\n",
       "         ('shup', 'ki'): 5,\n",
       "         ('phir', 'maine'): 5,\n",
       "         ('walon', 'ne'): 5,\n",
       "         ('aj', 'subah'): 5,\n",
       "         ('or', 'kuch'): 5,\n",
       "         ('chla', 'gya'): 5,\n",
       "         ('tab', 'tak'): 5,\n",
       "         ('or', 'us'): 5,\n",
       "         ('3', 'ghantay'): 5,\n",
       "         ('ke', 'ghar'): 5,\n",
       "         ('shuru', 'kar'): 5,\n",
       "         ('ka', 'irada'): 5,\n",
       "         ('gaye', 'aaj'): 5,\n",
       "         ('bed', 'par'): 5,\n",
       "         ('halka', 'sa'): 5,\n",
       "         ('family', 'ke'): 5,\n",
       "         ('agle', 'din'): 5,\n",
       "         ('aur', 'thodi'): 5,\n",
       "         ('ki', 'jo'): 5,\n",
       "         ('dost', 'se'): 5,\n",
       "         ('assignments', 'aur'): 5,\n",
       "         ('university', 'ki'): 5,\n",
       "         ('phir', 'ma'): 5,\n",
       "         ('doston', 'ka'): 5,\n",
       "         ('subha', '6'): 5,\n",
       "         ('aj', 'university'): 5,\n",
       "         ('baad', 'me'): 5,\n",
       "         ('yaad', 'aya'): 5,\n",
       "         ('baith', 'kar'): 5,\n",
       "         ('baad', 'mene'): 5,\n",
       "         ('kar', 'mein'): 5,\n",
       "         ('gaya', 'tha'): 5,\n",
       "         ('ann', 'ki'): 5,\n",
       "         ('ka', 'waqt'): 5,\n",
       "         ('beth', 'gaya'): 5,\n",
       "         ('dost', 'ka'): 5,\n",
       "         ('gaya', 'wahan'): 5,\n",
       "         ('parhi', 'phir'): 5,\n",
       "         ('aaj', 'subha'): 5,\n",
       "         ('dair', 'araam'): 5,\n",
       "         ('baje', 'university'): 5,\n",
       "         ('ho', 'gayi'): 5,\n",
       "         ('kar', 'raha'): 5,\n",
       "         ('din', 'tha'): 5,\n",
       "         ('uth', 'gaya'): 5,\n",
       "         ('karta', 'raha'): 5,\n",
       "         ('karte', 'karte'): 5,\n",
       "         ('ghar', 'per'): 5,\n",
       "         ('check', 'kiya'): 5,\n",
       "         ('wapas', 'aaya'): 5,\n",
       "         ('ke', 'aaj'): 5,\n",
       "         ('mein', 'aaj'): 5,\n",
       "         ('aur', 'baatein'): 5,\n",
       "         ('lecture', 'attend'): 5,\n",
       "         ('beth', 'kar'): 5,\n",
       "         ('namaz', 'adaa'): 5,\n",
       "         ('ki', 'tilawat'): 5,\n",
       "         ('tilawat', 'ki'): 5,\n",
       "         ('farigh', 'ho'): 5,\n",
       "         ('ke', 'class'): 5,\n",
       "         ('ke', 'kareeb'): 5,\n",
       "         ('dost', 'ki'): 5,\n",
       "         ('kei', 'sath'): 5,\n",
       "         ('jo', 'ke'): 5,\n",
       "         ('lekin', 'phir'): 5,\n",
       "         ('aur', 'chai'): 5,\n",
       "         ('cafe', 'se'): 5,\n",
       "         ('dosto', 'ke'): 5,\n",
       "         ('tha', 'jis'): 4,\n",
       "         ('ki', 'aj'): 4,\n",
       "         ('aur', 'wahan'): 4,\n",
       "         ('der', 'rest'): 4,\n",
       "         ('7', 'bjy'): 4,\n",
       "         ('ki', 'waja'): 4,\n",
       "         ('anda', 'paratha'): 4,\n",
       "         ('2', 'baje'): 4,\n",
       "         ('hum', 'ghar'): 4,\n",
       "         ('aaj', 'mai'): 4,\n",
       "         ('tayar', 'ho'): 4,\n",
       "         ('gaya', 'university'): 4,\n",
       "         ('cafe', 'chala'): 4,\n",
       "         ('bus', 'ka'): 4,\n",
       "         ('time', 'hogaya'): 4,\n",
       "         ('5', 'bajay'): 4,\n",
       "         ('aa', 'kar'): 4,\n",
       "         ('phir', 'khana'): 4,\n",
       "         ('pe', 'uthi'): 4,\n",
       "         ('aur', 'thori'): 4,\n",
       "         ('unke', 'sath'): 4,\n",
       "         ('class', 'lena'): 4,\n",
       "         ('free', 'hukr'): 4,\n",
       "         ('aur', 'mein'): 4,\n",
       "         ('classes', 'se'): 4,\n",
       "         ('nascon', 'ka'): 4,\n",
       "         ('youtube', 'dekha'): 4,\n",
       "         ('sath', 'chai'): 4,\n",
       "         ('ghar', 'ke'): 4,\n",
       "         ('shuru', 'kiya'): 4,\n",
       "         ('uss', 'ke'): 4,\n",
       "         ('khana', 'kha'): 4,\n",
       "         ('meri', 'dost'): 4,\n",
       "         ('khana', 'khane'): 4,\n",
       "         ('kr', 'diya'): 4,\n",
       "         ('to', 'mai'): 4,\n",
       "         ('rhe', 'the'): 4,\n",
       "         ('koshish', 'ki'): 4,\n",
       "         ('li', 'or'): 4,\n",
       "         ('nashta', 'banaya'): 4,\n",
       "         ('khanay', 'ke'): 4,\n",
       "         ('ki', 'namz'): 4,\n",
       "         ('namz', 'perhi'): 4,\n",
       "         ('gya', 'phir'): 4,\n",
       "         ('kuch', 'deer'): 4,\n",
       "         ('gya', 'university'): 4,\n",
       "         ('pm', 'per'): 4,\n",
       "         ('deep', 'learning'): 4,\n",
       "         ('phir', 'asr'): 4,\n",
       "         ('kuch', 'khaya'): 4,\n",
       "         ('gya', 'aj'): 4,\n",
       "         ('7', 'bajay'): 4,\n",
       "         ('phir', 'sab'): 4,\n",
       "         ('bhai', 'ko'): 4,\n",
       "         ('meri', 'class'): 4,\n",
       "         ('2', 'bajay'): 4,\n",
       "         ('wapis', 'ghar'): 4,\n",
       "         ('ki', 'tayari'): 4,\n",
       "         ('tayari', 'ki'): 4,\n",
       "         ('jaldi', 'uthna'): 4,\n",
       "         ('aa', 'ke'): 4,\n",
       "         ('so', 'gaye'): 4,\n",
       "         ('jo', 'kaafi'): 4,\n",
       "         ('kiya', 'nashta'): 4,\n",
       "         ('research', 'ki'): 4,\n",
       "         ('aur', 'social'): 4,\n",
       "         ('feel', 'ho'): 4,\n",
       "         ('walk', 'kiya'): 4,\n",
       "         ('ke', 'baare'): 4,\n",
       "         ('araam', 'se'): 4,\n",
       "         ('subah', 'jaldi'): 4,\n",
       "         ('liye', 'tayar'): 4,\n",
       "         ('lecture', 'ke'): 4,\n",
       "         ('break', 'mein'): 4,\n",
       "         ('aur', 'neend'): 4,\n",
       "         ('jumma', 'ki'): 4,\n",
       "         ('sath', 'khana'): 4,\n",
       "         ('khaya', 'or'): 4,\n",
       "         ('sath', 'bahar'): 4,\n",
       "         ('lag', 'gaya'): 4,\n",
       "         ('aj', 'mein'): 4,\n",
       "         ('ja', 'kar'): 4,\n",
       "         ('classes', 'attend'): 4,\n",
       "         ('baad', 'khana'): 4,\n",
       "         ('aj', 'main'): 4,\n",
       "         ('dost', 'ky'): 4,\n",
       "         ('to', 'main'): 4,\n",
       "         ('us', 'ky'): 4,\n",
       "         ('class', 'ka'): 4,\n",
       "         ('time', 'ho'): 4,\n",
       "         ('kch', 'dair'): 4,\n",
       "         ('aa', 'gay'): 4,\n",
       "         ('mil', 'kr'): 4,\n",
       "         ('tha', 'wo'): 4,\n",
       "         ('main', 'apny'): 4,\n",
       "         ('or', 'so'): 4,\n",
       "         ('aj', 'me'): 4,\n",
       "         ('football', 'khelne'): 4,\n",
       "         ('ne', 'apne'): 4,\n",
       "         ('ka', 'bhi'): 4,\n",
       "         ('maza', 'aya'): 4,\n",
       "         ('4', 'baje'): 4,\n",
       "         ('11', 'baje'): 4,\n",
       "         ('kiye', 'phir'): 4,\n",
       "         ('phir', 'thori'): 4,\n",
       "         ('tha', 'toh'): 4,\n",
       "         ('k', 'quiz'): 4,\n",
       "         ('ho', 'rahi'): 4,\n",
       "         ('free', 'ho'): 4,\n",
       "         ('ghar', 'ka'): 4,\n",
       "         ('mein', 'subha'): 4,\n",
       "         ('aa', 'gaye'): 4,\n",
       "         ('ne', 'mil'): 4,\n",
       "         ('kai', 'liye'): 4,\n",
       "         ('time', 'spend'): 4,\n",
       "         ('bajay', 'university'): 4,\n",
       "         ('ke', 'kuch'): 4,\n",
       "         ('baad', 'thoda'): 4,\n",
       "         ('baad', 'ek'): 4,\n",
       "         ('taake', 'kal'): 4,\n",
       "         ('aur', 'ghar'): 4,\n",
       "         ('baad', 'nashta'): 4,\n",
       "         ('pass', 'chala'): 4,\n",
       "         ('kr', 'k'): 4,\n",
       "         ('bjy', 'tak'): 4,\n",
       "         ('sath', 'time'): 4,\n",
       "         ('11', 'bjy'): 4,\n",
       "         ('fajar', 'ki'): 4,\n",
       "         ('se', 'le'): 4,\n",
       "         ('hua', 'to'): 4,\n",
       "         ('araam', 'kia'): 4,\n",
       "         ('baad', 'maine'): 4,\n",
       "         ('main', 'so'): 4,\n",
       "         ('mein', 'ny'): 4,\n",
       "         ('dinner', 'kia'): 4,\n",
       "         ('hui', 'aur'): 4,\n",
       "         ('networks', 'ki'): 4,\n",
       "         ('9', 'baje'): 4,\n",
       "         ('se', 'bhi'): 4,\n",
       "         ('samajh', 'nahi'): 4,\n",
       "         ('se', 'baat'): 4,\n",
       "         ('bajay', 'uth'): 4,\n",
       "         ('beech', 'beech'): 4,\n",
       "         ('beech', 'mein'): 4,\n",
       "         ('ne', 'kaha'): 4,\n",
       "         ('kaha', 'ke'): 4,\n",
       "         ('aa', 'gayi'): 4,\n",
       "         ('din', 'ka'): 4,\n",
       "         ('se', 'wapas'): 4,\n",
       "         ('kashmir', 'day'): 4,\n",
       "         ('aya', 'ke'): 4,\n",
       "         ('tha', 'ke'): 4,\n",
       "         ('phir', 'bhi'): 4,\n",
       "         ('bajay', 'uthi'): 4,\n",
       "         ('kaam', 'kiye'): 4,\n",
       "         ('kaam', 'karnay'): 4,\n",
       "         ('apni', 'assignment'): 4,\n",
       "         ('der', 'baad'): 4,\n",
       "         ('scrolling', 'ki'): 4,\n",
       "         ('thoda', 'late'): 4,\n",
       "         ('ankh', 'khuli'): 4,\n",
       "         ('or', 'sath'): 4,\n",
       "         ('quran', 'ki'): 4,\n",
       "         ('liye', 'rawana'): 4,\n",
       "         ('computer', 'networks'): 4,\n",
       "         ('nlp', 'ke'): 4,\n",
       "         ('subha', '10'): 4,\n",
       "         ('ko', 'call'): 4,\n",
       "         ('baje', 'ke'): 4,\n",
       "         ('nahaya', 'aur'): 4,\n",
       "         ('aur', 'mei'): 4,\n",
       "         ('a', 'kar'): 4,\n",
       "         ('aik', 'dost'): 4,\n",
       "         ('kae', 'baad'): 4,\n",
       "         ('kae', 'liye'): 4,\n",
       "         ('karna', 'shuru'): 4,\n",
       "         ('12:00', 'baje'): 4,\n",
       "         ('1:00', 'baje'): 4,\n",
       "         ('baad', 'doston'): 4,\n",
       "         ('gym', 'gaya'): 4,\n",
       "         ('bhook', 'lagi'): 4,\n",
       "         ('hi', 'nahi'): 4,\n",
       "         ('phir', 'thora'): 4,\n",
       "         ('lunch', 'ke'): 4,\n",
       "         ('banayi', 'aur'): 4,\n",
       "         ('hai', 'ke'): 4,\n",
       "         ('ke', 'pass'): 4,\n",
       "         ('k', 'badh'): 4,\n",
       "         ('gya', 'aur'): 4,\n",
       "         ('main', 'ne'): 4,\n",
       "         ('room', 'me'): 4,\n",
       "         ('hua', 'aur'): 3,\n",
       "         ('aa', 'gaya'): 3,\n",
       "         ('8', 'bjy'): 3,\n",
       "         ('bjy', 'utha'): 3,\n",
       "         ('aur', 'aj'): 3,\n",
       "         ('university', 'ponch'): 3,\n",
       "         ('ka', 'tha'): 3,\n",
       "         ('se', 'ghar'): 3,\n",
       "         ('liye', 'chala'): 3,\n",
       "         ('aur', 'kaafi'): 3,\n",
       "         ('gaya', 'subah'): 3,\n",
       "         ('nashta', 'tayar'): 3,\n",
       "         ('class', 'cancel'): 3,\n",
       "         ('shup', 'lagayi'): 3,\n",
       "         ('kapre', 'istri'): 3,\n",
       "         ('drop', 'kiya'): 3,\n",
       "         ('uske', 'sath'): 3,\n",
       "         ('baad', 'chaye'): 3,\n",
       "         ('12', 'baje'): 3,\n",
       "         ('baje', 'ghar'): 3,\n",
       "         ('mai', 'ne'): 3,\n",
       "         ('khana', 'khany'): 3,\n",
       "         ('namaz', 'parhe'): 3,\n",
       "         ('ko', 'bus'): 3,\n",
       "         ('family', 'k'): 3,\n",
       "         ('bajay', 'so'): 3,\n",
       "         ('mein', 'subh'): 3,\n",
       "         ('lya', 'nikal'): 3,\n",
       "         ('nikal', 'gayi'): 3,\n",
       "         ('quiz', 'tha'): 3,\n",
       "         ('tu', 'mein'): 3,\n",
       "         ('quiz', 'tyar'): 3,\n",
       "         ('kya', 'aur'): 3,\n",
       "         ('ka', 'break'): 3,\n",
       "         ('pdc', 'ka'): 3,\n",
       "         ('hum', 'apni'): 3,\n",
       "         ('pi', 'aur'): 3,\n",
       "         ('kaam', 'complete'): 3,\n",
       "         ('uthi', 'nashta'): 3,\n",
       "         ('kiya', 'thori'): 3,\n",
       "         ('tk', 'free'): 3,\n",
       "         ('sath', 'sath'): 3,\n",
       "         ('complete', 'kiya'): 3,\n",
       "         ('sab', 'ke'): 3,\n",
       "         ('ne', 'thori'): 3,\n",
       "         ('liya', 'aur'): 3,\n",
       "         ('kha', 'liya'): 3,\n",
       "         ('meeting', 'attend'): 3,\n",
       "         ('ka', 'home'): 3,\n",
       "         ('us', 'ke'): 3,\n",
       "         ('tiyari', 'ki'): 3,\n",
       "         ('namaz', 'prhi'): 3,\n",
       "         ('kuch', 'dair'): 3,\n",
       "         ('apna', 'kaam'): 3,\n",
       "         ('a', 'gyi'): 3,\n",
       "         ('ki', '11:30'): 3,\n",
       "         ('dip', 'ki'): 3,\n",
       "         ('library', 'mein'): 3,\n",
       "         ('ann', 'ka'): 3,\n",
       "         ('parha', 'aur'): 3,\n",
       "         ('khane', 'ke'): 3,\n",
       "         ('uthne', 'ka'): 3,\n",
       "         ('ne', 'mujhe'): 3,\n",
       "         ('uni', 'ke'): 3,\n",
       "         ('uni', 'se'): 3,\n",
       "         ('hi', 'tha'): 3,\n",
       "         ('mai', 'phir'): 3,\n",
       "         ('rhi', 'thi'): 3,\n",
       "         ('sir', 'ne'): 3,\n",
       "         ('to', 'ham'): 3,\n",
       "         ('hoti', 'hai'): 3,\n",
       "         ('neend', 'bhi'): 3,\n",
       "         ('aati', 'hai'): 3,\n",
       "         ('hai', 'to'): 3,\n",
       "         ('break', 'thi'): 3,\n",
       "         ('baad', 'ham'): 3,\n",
       "         ('se', 'kuch'): 3,\n",
       "         ('kuch', 'kaam'): 3,\n",
       "         ('rha', 'tha'): 3,\n",
       "         ('akhir', 'kaar'): 3,\n",
       "         ('gae', 'the'): 3,\n",
       "         ('or', 'baba'): 3,\n",
       "         ('chai', 'ke'): 3,\n",
       "         ('sone', 'se'): 3,\n",
       "         ('abhi', 'tak'): 3,\n",
       "         ('to', 'kuch'): 3,\n",
       "         ('mein', 'subah'): 3,\n",
       "         ('liye', 'nashta'): 3,\n",
       "         ('apne', 'liye'): 3,\n",
       "         ('banaya', 'aur'): 3,\n",
       "         ('tyar', 'hui'): 3,\n",
       "         ('liye', 'tyar'): 3,\n",
       "         ('hum', 'sab'): 3,\n",
       "         ('mein', 'jaldi'): 3,\n",
       "         ('jaldi', 'so'): 3,\n",
       "         ('perhi', 'or'): 3,\n",
       "         ('mu', 'hath'): 3,\n",
       "         ('phir', 'nahaya'): 3,\n",
       "         ('sath', 'cafe'): 3,\n",
       "         ('asr', 'ki'): 3,\n",
       "         ('university', 'sa'): 3,\n",
       "         ('a', 'ker'): 3,\n",
       "         ('ami', 'abu'): 3,\n",
       "         ('ki', 'raat'): 3,\n",
       "         ('ka', 'kam'): 3,\n",
       "         ('subah', 'ma'): 3,\n",
       "         ('utha', 'phir'): 3,\n",
       "         ('huwa', 'tha'): 3,\n",
       "         ('us', 'ka'): 3,\n",
       "         ('namaz', 'padhi'): 3,\n",
       "         ('ghar', 'aya'): 3,\n",
       "         ('tak', 'so'): 3,\n",
       "         ('dost', 'ke'): 3,\n",
       "         ('hum', 'dono'): 3,\n",
       "         ('der', 'mobile'): 3,\n",
       "         ('relax', 'kiya'): 3,\n",
       "         ('kiya', 'ghar'): 3,\n",
       "         ('kiya', 'jo'): 3,\n",
       "         ('tha', 'nashta'): 3,\n",
       "         ('aur', 'ek'): 3,\n",
       "         ('kaafi', 'acha'): 3,\n",
       "         ('thoda', 'fresh'): 3,\n",
       "         ('ghar', 'aakar'): 3,\n",
       "         ('assignments', 'complete'): 3,\n",
       "         ('enjoy', 'kiya'): 3,\n",
       "         ('kiya', 'raat'): 3,\n",
       "         ('ko', 'ek'): 3,\n",
       "         ('music', 'suna'): 3,\n",
       "         ('suna', 'aur'): 3,\n",
       "         ('aur', 'apne'): 3,\n",
       "         ('din', 'ke'): 3,\n",
       "         ('baare', 'mein'): 3,\n",
       "         ('let', 'gaya'): 3,\n",
       "         ('aur', 'araam'): 3,\n",
       "         ('kaam', 'ke'): 3,\n",
       "         ('hone', 'laga'): 3,\n",
       "         ('par', 'pohanch'): 3,\n",
       "         ('pohanch', 'gaya'): 3,\n",
       "         ('gaya', 'pehli'): 3,\n",
       "         ('kaafi', 'interesting'): 3,\n",
       "         ('shuru', 'ho'): 3,\n",
       "         ('lunch', 'break'): 3,\n",
       "         ('liye', 'research'): 3,\n",
       "         ('bhi', 'ki'): 3,\n",
       "         ('classes', 'ke'): 3,\n",
       "         ('phir', 'thodi'): 3,\n",
       "         ('aur', 'din'): 3,\n",
       "         ('namaz', 'ke'): 3,\n",
       "         ('baad', 'apni'): 3,\n",
       "         ('project', 'par'): 3,\n",
       "         ('ma', 'apna'): 3,\n",
       "         ('dost', 'ko'): 3,\n",
       "         ('or', 'ma'): 3,\n",
       "         ('wapis', 'a'): 3,\n",
       "         ('kaam', 'karna'): 3,\n",
       "         ('movie', 'dekhi'): 3,\n",
       "         ('dekhi', 'or'): 3,\n",
       "         ('k', 'saath'): 3,\n",
       "         ('a', 'gai'): 3,\n",
       "         ('gai', 'or'): 3,\n",
       "         ('ho', 'gai'): 3,\n",
       "         ('gai', 'phir'): 3,\n",
       "         ('unho', 'ne'): 3,\n",
       "         ('ma', 'subha'): 3,\n",
       "         ('aur', 'fajr'): 3,\n",
       "         ('class', 'k'): 3,\n",
       "         ('chaly', 'gay'): 3,\n",
       "         ('thora', 'rest'): 3,\n",
       "         ('phir', 'dost'): 3,\n",
       "         ('10', 'bjy'): 3,\n",
       "         ('main', 'university'): 3,\n",
       "         ('gya', 'or'): 3,\n",
       "         ('krna', 'tha'): 3,\n",
       "         ('mila', 'to'): 3,\n",
       "         ('phir', 'meri'): 3,\n",
       "         ('ho', 'gya'): 3,\n",
       "         ('ki', 'us'): 3,\n",
       "         ('ak', 'dost'): 3,\n",
       "         ('hum', 'ny'): 3,\n",
       "         ('ak', 'or'): 3,\n",
       "         ('or', 'dost'): 3,\n",
       "         ('gay', 'phir'): 3,\n",
       "         ('ghar', 'chala'): 3,\n",
       "         ('doston', 'ky'): 3,\n",
       "         ('me', 'ne'): 3,\n",
       "         ('dosto', 'ko'): 3,\n",
       "         ('tha', 'jiski'): 3,\n",
       "         ('jiski', 'waja'): 3,\n",
       "         ('khelne', 'k'): 3,\n",
       "         ('namaz', 'parhne'): 3,\n",
       "         ('karne', 'k'): 3,\n",
       "         ('kar', 'university'): 3,\n",
       "         ('university', 'janay'): 3,\n",
       "         ('tyaar', 'hua'): 3,\n",
       "         ('saath', 'baith'): 3,\n",
       "         ('aam', 'tor'): 3,\n",
       "         ('lag', 'rahi'): 3,\n",
       "         ('dair', 'walk'): 3,\n",
       "         ('youtube', 'par'): 3,\n",
       "         ('random', 'videos'): 3,\n",
       "         ('raha', 'aur'): 3,\n",
       "         ('lait', 'gaya'): 3,\n",
       "         ('thi', 'aj'): 3,\n",
       "         ('kiya', 'shaam'): 3,\n",
       "         ('11:30', 'baje'): 3,\n",
       "         ('phir', 'mene'): 3,\n",
       "         ('thi', 'ke'): 3,\n",
       "         ('phir', 'raat'): 3,\n",
       "         ('liye', 'phir'): 3,\n",
       "         ('mein', 'doston'): 3,\n",
       "         ('cafe', 'mein'): 3,\n",
       "         ('5', 'baje'): 3,\n",
       "         ('wapis', 'hostel'): 3,\n",
       "         ('nahi', 'hua'): 3,\n",
       "         ('subha', 'jaldi'): 3,\n",
       "         ('aur', '8:30'): 3,\n",
       "         ('free', 'time'): 3,\n",
       "         ('ke', 'lecture'): 3,\n",
       "         ('aur', 'projects'): 3,\n",
       "         ('ka', 'socha'): 3,\n",
       "         ('phir', 'ham'): 3,\n",
       "         ('nascon', 'room'): 3,\n",
       "         ('thi', 'wo'): 3,\n",
       "         ('message', 'aya'): 3,\n",
       "         ('wahan', 'say'): 3,\n",
       "         ('aur', 'aik'): 3,\n",
       "         ('aur', 'sab'): 3,\n",
       "         ('bhi', 'thori'): 3,\n",
       "         ('baad', 'ghar'): 3,\n",
       "         ('dost', 'k'): 3,\n",
       "         ('5:15', 'tak'): 3,\n",
       "         ('university', 'kay'): 3,\n",
       "         ('ghar', 'se'): 3,\n",
       "         ('nikal', 'gya'): 3,\n",
       "         ('1', 'se'): 3,\n",
       "         ('gari', 'mein'): 3,\n",
       "         ('tak', 'ghar'): 3,\n",
       "         ('us', 'kay'): 3,\n",
       "         ('sonay', 'se'): 3,\n",
       "         ('or', 'phr'): 3,\n",
       "         ('gym', 'se'): 3,\n",
       "         ('se', 'wapis'): 3,\n",
       "         ('gaya', 'wapis'): 3,\n",
       "         ('scroll', 'kia'): 3,\n",
       "         ('gaya', '1'): 3,\n",
       "         ('nashta', 'late'): 3,\n",
       "         ('mein', 'bus'): 3,\n",
       "         ('phir', 'bus'): 3,\n",
       "         ('allah', 'hafiz'): 3,\n",
       "         ('baje', 'uth'): 3,\n",
       "         ('uth', 'gayi'): 3,\n",
       "         ('university', 'pohanch'): 3,\n",
       "         ('kar', 'class'): 3,\n",
       "         ('se', 'mili'): 3,\n",
       "         ('tor', 'par'): 3,\n",
       "         ('aaj', 'ki'): 3,\n",
       "         ('relax', 'kia'): 3,\n",
       "         ('kar', 'liya'): 3,\n",
       "         ('ban', 'gaya'): 3,\n",
       "         ('bina', 'kisi'): 3,\n",
       "         ('1', 'aaj'): 3,\n",
       "         ('jaana', 'tha'): 3,\n",
       "         ('mood', 'nahi'): 3,\n",
       "         ('nahi', 'kar'): 3,\n",
       "         ('weekend', 'ka'): 3,\n",
       "         ('hai', 'isliye'): 3,\n",
       "         ('magar', 'phir'): 3,\n",
       "         ('ka', 'intezar'): 3,\n",
       "         ('karte', 'neend'): 3,\n",
       "         ('aur', 'shaam'): 3,\n",
       "         ('chalte', 'hain'): 3,\n",
       "         ('baad', 'kuch'): 3,\n",
       "         ('ke', 'din'): 3,\n",
       "         ('aur', 'doston'): 3,\n",
       "         ('laptop', 'khola'): 3,\n",
       "         ('baad', 'wapis'): 3,\n",
       "         ('kay', 'liye'): 3,\n",
       "         ('pi', 'phir'): 3,\n",
       "         ('phir', 'aik'): 3,\n",
       "         ('aur', 'bahir'): 3,\n",
       "         ('karnay', 'kay'): 3,\n",
       "         ('kar', 'ghar'): 3,\n",
       "         ('subah', '7'): 3,\n",
       "         ('aur', '9'): 3,\n",
       "         ('mein', 'gayi'): 3,\n",
       "         ('lenay', 'kay'): 3,\n",
       "         ('ki', '11'): 3,\n",
       "         ('late', 'utha'): 3,\n",
       "         ('aaya', 'aur'): 3,\n",
       "         ('achay', 'se'): 3,\n",
       "         ('se', 'nashta'): 3,\n",
       "         ('kiya', 'alhamdullilah'): 3,\n",
       "         ('ki', 'call'): 3,\n",
       "         ('der', 'baat'): 3,\n",
       "         ('zuhr', 'ki'): 3,\n",
       "         ('kartay', 'kartay'): 3,\n",
       "         ('phir', 'apni'): 3,\n",
       "         ('hostel', 'ka'): 3,\n",
       "         ('khanay', 'k'): 3,\n",
       "         ('gai', 'aaj'): 3,\n",
       "         ('tou', 'mai'): 3,\n",
       "         ('hui', 'phir'): 3,\n",
       "         ('ho', 'gaye'): 3,\n",
       "         ('baatein', 'kin'): 3,\n",
       "         ('mai', 'hi'): 3,\n",
       "         ('ki', 'lab'): 3,\n",
       "         ('wajah', 'sai'): 3,\n",
       "         ('hui', 'thi'): 3,\n",
       "         ('bus', 'se'): 3,\n",
       "         ('kar', 'hostel'): 3,\n",
       "         ('kar', 'jab'): 3,\n",
       "         ('karti', 'rahi'): 3,\n",
       "         ('acha', 'laga'): 3,\n",
       "         ('dho', 'kar'): 3,\n",
       "         ('tha', 'kal'): 3,\n",
       "         ('par', 'kuch'): 3,\n",
       "         ('khatam', 'hone'): 3,\n",
       "         ('hai', 'or'): 3,\n",
       "         ('kaha', 'k'): 3,\n",
       "         ('apnay', 'dost'): 3,\n",
       "         ('1', 'bajay'): 3,\n",
       "         ('to', 'mei'): 3,\n",
       "         ('kar', 'mei'): 3,\n",
       "         ('baba', 'kei'): 3,\n",
       "         ('parhnay', 'chala'): 3,\n",
       "         ('wudu', 'kiya'): 3,\n",
       "         ('parh', 'kar'): 3,\n",
       "         ('apnay', 'ghar'): 3,\n",
       "         ('liye', 'nikla'): 3,\n",
       "         ('2', 'ghantay'): 3,\n",
       "         ('phir', 'ek'): 3,\n",
       "         ('ek', 'dost'): 3,\n",
       "         ('aur', 'kal'): 3,\n",
       "         ('or', 'aaj'): 3,\n",
       "         ('kar', 'fresh'): 3,\n",
       "         ('set', 'kia'): 3,\n",
       "         ('dhoya', 'aur'): 3,\n",
       "         ('poora', 'din'): 3,\n",
       "         ('kapray', 'pehn'): 3,\n",
       "         ('aaj', 'meri'): 3,\n",
       "         ('kaam', 'ka'): 3,\n",
       "         ('lagi', 'thi'): 3,\n",
       "         ('thi', 'lekin'): 3,\n",
       "         ('karna', 'tha'): 3,\n",
       "         ('loon', 'lekin'): 3,\n",
       "         ('mushkil', 'hota'): 3,\n",
       "         ('aur', 'thora'): 3,\n",
       "         ('7:30', 'bajay'): 3,\n",
       "         ('ek', 'aur'): 3,\n",
       "         ('fresh', 'ho'): 3,\n",
       "         ('ke', 'sab'): 3,\n",
       "         ('kar', 'chai'): 3,\n",
       "         ('8', 'baje'): 3,\n",
       "         ('ke', 'ye'): 3,\n",
       "         ('kar', 'di'): 3,\n",
       "         ('fresh', 'hone'): 3,\n",
       "         ('start', 'kar'): 3,\n",
       "         ('raha', 'hai'): 3,\n",
       "         ('kya', 'lekin'): 3,\n",
       "         ('lagi', 'to'): 3,\n",
       "         ('sath', 'me'): 3,\n",
       "         ('likh', 'raha'): 3,\n",
       "         ('irada', 'hai'): 3,\n",
       "         ('k', 'lie'): 3,\n",
       "         ('hath', 'dho'): 3,\n",
       "         ('ami', 'k'): 3,\n",
       "         ('ki', 'kuch'): 3,\n",
       "         ('se', 'mil'): 3,\n",
       "         ('main', 'subha'): 3,\n",
       "         ('aur', 'kapray'): 3,\n",
       "         ('keh', 'baad'): 3,\n",
       "         ('dawai', 'li'): 3,\n",
       "         ('ke', 'so'): 3,\n",
       "         ('me', 'bet'): 3,\n",
       "         ('karnay', 'ke'): 3,\n",
       "         ('hone', 'ke'): 3,\n",
       "         ('ami', 'ke'): 3,\n",
       "         ('ho', 'wa'): 3,\n",
       "         ('wa', 'tha'): 3,\n",
       "         ('gaye', 'tha'): 3,\n",
       "         ('ghar', 'aake'): 3,\n",
       "         ('office', 'se'): 3,\n",
       "         ('kea', 'or'): 3,\n",
       "         ('subha', '5'): 2,\n",
       "         ('kee', 'phir'): 2,\n",
       "         ('mil', 'gaya'): 2,\n",
       "         ('picks', 'leen'): 2,\n",
       "         ('phir', 'dinner'): 2,\n",
       "         ('subah', '8'): 2,\n",
       "         ('utha', 'fresh'): 2,\n",
       "         ('liye', 'tyaar'): 2,\n",
       "         ('9', 'bjy'): 2,\n",
       "         ('bike', 'pe'): 2,\n",
       "         ('ha', 'aur'): 2,\n",
       "         ('sirf', '2'): 2,\n",
       "         ('hain', 'university'): 2,\n",
       "         ('pehla', 'lecture'): 2,\n",
       "         ('jis', 'me'): 2,\n",
       "         ('maza', 'aata'): 2,\n",
       "         ('q', 'k'): 2,\n",
       "         ('classes', 'lene'): 2,\n",
       "         ('liye', 'nikl'): 2,\n",
       "         ('jummah', 'se'): 2,\n",
       "         ('ponch', 'gaya'): 2,\n",
       "         ('gaya', 'jummah'): 2,\n",
       "         ('aur', 'apnay'): 2,\n",
       "         ('gaoon', 'k'): 2,\n",
       "         ('aur', 'takreebn'): 2,\n",
       "         ('bjy', 'tk'): 2,\n",
       "         ('hm', 'log'): 2,\n",
       "         ('log', 'gaoon'): 2,\n",
       "         ('mene', 'thori'): 2,\n",
       "         ('wapsi', 'pe'): 2,\n",
       "         ('subah', 'uth'): 2,\n",
       "         ('gaya', 'lekin'): 2,\n",
       "         ('mehmano', 'k'): 2,\n",
       "         ('istri', 'kiye'): 2,\n",
       "         ('kiye', 'or'): 2,\n",
       "         ('k', 'ghar'): 2,\n",
       "         ('rasty', 'mai'): 2,\n",
       "         ('salar', 'ko'): 2,\n",
       "         ('k', 'qareeb'): 2,\n",
       "         ('or', 'hum'): 2,\n",
       "         ('dental', 'clinic'): 2,\n",
       "         ('ja', 'raha'): 2,\n",
       "         ('gaye', 'or'): 2,\n",
       "         ('or', '12'): 2,\n",
       "         ('ghar', 'pohancha'): 2,\n",
       "         ('pohancha', 'ghar'): 2,\n",
       "         ('insta', 'scroll'): 2,\n",
       "         ('sogaya', 'aaj'): 2,\n",
       "         ('k', 'university'): 2,\n",
       "         ('min', 'late'): 2,\n",
       "         ('computing', 'ki'): 2,\n",
       "         ('classes', 'k'): 2,\n",
       "         ('phir', 'jummah'): 2,\n",
       "         ('jummah', 'k'): 2,\n",
       "         ('khaya', 'khana'): 2,\n",
       "         ('bad', 'mai'): 2,\n",
       "         ('mai', 'ghar'): 2,\n",
       "         ('kyun', 'k'): 2,\n",
       "         ('home', 'town'): 2,\n",
       "         ('intizar', 'kia'): 2,\n",
       "         ('mai', 'bus'): 2,\n",
       "         ('tora', 'sa'): 2,\n",
       "         ('waha', 'par'): 2,\n",
       "         ('khaya', 'us'): 2,\n",
       "         ('walk', 'ki'): 2,\n",
       "         ('sa', 'waqt'): 2,\n",
       "         ('guzara', 'aur'): 2,\n",
       "         ('hu', 'kr'): 2,\n",
       "         ('kr', 'university'): 2,\n",
       "         ('9:30', 'tk'): 2,\n",
       "         ('tk', 'university'): 2,\n",
       "         ('university', 'pohunch'): 2,\n",
       "         ...})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_count = Counter(tokens)\n",
    "bigram_count = Counter(bigrams)\n",
    "trigram_count = Counter(trigrams)\n",
    "# trigram_count['chala', 'gaya', '.']\n",
    "# trigram_count\n",
    "bigram_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "096f87e6-885f-480b-8227-02ab6d0c46a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {('subha', '5'): 0.047619047619047616,\n",
       "             ('5', 'bjhey'): 0.06666666666666667,\n",
       "             ('bjhey', 'uthna'): 1.0,\n",
       "             ('uthna', 'perha'): 0.16666666666666666,\n",
       "             ('perha', 'trip'): 1.0,\n",
       "             ('trip', 'thaa'): 0.14285714285714285,\n",
       "             ('thaa', 'jaldi'): 0.14285714285714285,\n",
       "             ('jaldi', 'jaldi'): 0.18181818181818182,\n",
       "             ('jaldi', 'ready'): 0.022727272727272728,\n",
       "             ('ready', 'hua'): 0.3333333333333333,\n",
       "             ('hua', 'aur'): 0.0967741935483871,\n",
       "             ('aur', '0540'): 0.00211864406779661,\n",
       "             ('0540', 'ghar'): 1.0,\n",
       "             ('ghar', 'saay'): 0.006578947368421052,\n",
       "             ('saay', 'nikal'): 0.3333333333333333,\n",
       "             ('nikal', 'gaay'): 0.037037037037037035,\n",
       "             ('gaay', '0615'): 0.1,\n",
       "             ('0615', 'bus'): 1.0,\n",
       "             ('bus', 'chal'): 0.03125,\n",
       "             ('chal', 'perhee'): 0.16666666666666666,\n",
       "             ('perhee', 'joo'): 1.0,\n",
       "             ('joo', 'kaay'): 1.0,\n",
       "             ('kaay', 'first'): 0.14285714285714285,\n",
       "             ('first', 'time'): 1.0,\n",
       "             ('time', 'thaa'): 0.02040816326530612,\n",
       "             ('thaa', 'kaay'): 0.14285714285714285,\n",
       "             ('kaay', 'trip'): 0.14285714285714285,\n",
       "             ('trip', 'time'): 0.14285714285714285,\n",
       "             ('time', 'saay'): 0.02040816326530612,\n",
       "             ('saay', 'chala'): 0.3333333333333333,\n",
       "             ('chala', 'nust'): 0.015873015873015872,\n",
       "             ('nust', 'kaay'): 1.0,\n",
       "             ('kaay', '3'): 0.14285714285714285,\n",
       "             ('3', 'larkay'): 0.0625,\n",
       "             ('larkay', 'thy'): 1.0,\n",
       "             ('thy', 'unsaay'): 0.125,\n",
       "             ('unsaay', 'batain'): 1.0,\n",
       "             ('batain', 'kee'): 0.25,\n",
       "             ('kee', 'phir'): 1.0,\n",
       "             ('phir', 'bluetooth'): 0.0030864197530864196,\n",
       "             ('bluetooth', 'trip'): 0.5,\n",
       "             ('trip', 'coordinator'): 0.14285714285714285,\n",
       "             ('coordinator', 'kaay'): 1.0,\n",
       "             ('kaay', 'pass'): 0.14285714285714285,\n",
       "             ('pass', 'thaa'): 0.1,\n",
       "             ('thaa', 'tou'): 0.14285714285714285,\n",
       "             ('tou', 'humm'): 0.038461538461538464,\n",
       "             ('humm', 'shoor'): 1.0,\n",
       "             ('shoor', 'daltay'): 1.0,\n",
       "             ('daltay', 'rahay'): 1.0,\n",
       "             ('rahay', 'kaay'): 0.16666666666666666,\n",
       "             ('kaay', 'song'): 0.14285714285714285,\n",
       "             ('song', 'change'): 1.0,\n",
       "             ('change', 'krr'): 0.14285714285714285,\n",
       "             ('krr', 'dain'): 1.0,\n",
       "             ('dain', 'phir'): 1.0,\n",
       "             ('phir', 'murree'): 0.0030864197530864196,\n",
       "             ('murree', 'mein'): 1.0,\n",
       "             ('mein', 'nashtay'): 0.0055248618784530384,\n",
       "             ('nashtay', 'kaay'): 0.125,\n",
       "             ('kaay', 'leya'): 0.14285714285714285,\n",
       "             ('leya', 'uthay'): 0.3333333333333333,\n",
       "             ('uthay', 'phir'): 1.0,\n",
       "             ('phir', 'usskay'): 0.0030864197530864196,\n",
       "             ('usskay', 'baad'): 1.0,\n",
       "             ('baad', 'bluetooth'): 0.004524886877828055,\n",
       "             ('bluetooth', 'humain'): 0.5,\n",
       "             ('humain', 'mil'): 1.0,\n",
       "             ('mil', 'gaya'): 0.10526315789473684,\n",
       "             ('gaya', 'mein'): 0.005847953216374269,\n",
       "             ('mein', 'tou'): 0.0055248618784530384,\n",
       "             ('tou', 'soogaya'): 0.038461538461538464,\n",
       "             ('soogaya', 'phir'): 1.0,\n",
       "             ('phir', 'hum'): 0.037037037037037035,\n",
       "             ('hum', 'jaga'): 0.018518518518518517,\n",
       "             ('jaga', 'prr'): 0.3333333333333333,\n",
       "             ('prr', 'phouch'): 0.25,\n",
       "             ('phouch', 'gaay'): 1.0,\n",
       "             ('gaay', 'udhar'): 0.1,\n",
       "             ('udhar', '3'): 0.5,\n",
       "             ('3', 'peaks'): 0.0625,\n",
       "             ('peaks', 'theen'): 1.0,\n",
       "             ('theen', '2'): 0.25,\n",
       "             ('2', 'perr'): 0.04,\n",
       "             ('perr', 'char'): 1.0,\n",
       "             ('char', 'gaay'): 1.0,\n",
       "             ('gaay', 'aik'): 0.1,\n",
       "             ('aik', 'prr'): 0.03333333333333333,\n",
       "             ('prr', 'sahi'): 0.25,\n",
       "             ('sahi', 'ghalat'): 0.2,\n",
       "             ('ghalat', 'raastay'): 1.0,\n",
       "             ('raastay', 'saay'): 0.3333333333333333,\n",
       "             ('saay', 'gaay'): 0.3333333333333333,\n",
       "             ('gaay', 'thy'): 0.1,\n",
       "             ('thy', 'full'): 0.125,\n",
       "             ('full', 'steep'): 1.0,\n",
       "             ('steep', 'thaa'): 1.0,\n",
       "             ('thaa', 'mujhey'): 0.14285714285714285,\n",
       "             ('mujhey', 'tou'): 1.0,\n",
       "             ('tou', 'laga'): 0.038461538461538464,\n",
       "             ('laga', 'mein'): 0.05263157894736842,\n",
       "             ('mein', 'gaya'): 0.0055248618784530384,\n",
       "             ('gaya', 'peak'): 0.005847953216374269,\n",
       "             ('peak', 'prr'): 1.0,\n",
       "             ('prr', 'pohouch'): 0.25,\n",
       "             ('pohouch', 'gaya'): 1.0,\n",
       "             ('gaya', 'phir'): 0.05263157894736842,\n",
       "             ('phir', 'picks'): 0.0030864197530864196,\n",
       "             ('picks', 'leen'): 1.0,\n",
       "             ('leen', 'phir'): 0.5,\n",
       "             ('phir', 'slow'): 0.0030864197530864196,\n",
       "             ('slow', 'wala'): 1.0,\n",
       "             ('wala', 'group'): 0.2,\n",
       "             ('group', 'bhee'): 0.16666666666666666,\n",
       "             ('bhee', 'aa'): 1.0,\n",
       "             ('aa', 'gaya'): 0.06666666666666667,\n",
       "             ('gaya', 'thaa'): 0.005847953216374269,\n",
       "             ('thaa', 'unn'): 0.14285714285714285,\n",
       "             ('unn', 'kaay'): 0.5,\n",
       "             ('kaay', 'sath'): 0.14285714285714285,\n",
       "             ('sath', 'dubara'): 0.009708737864077669,\n",
       "             ('dubara', 'picks'): 0.2,\n",
       "             ('leen', 'wapsi'): 0.5,\n",
       "             ('wapsi', 'prr'): 0.16666666666666666,\n",
       "             ('prr', 'jeep'): 0.25,\n",
       "             ('jeep', 'mein'): 1.0,\n",
       "             ('mein', 'bohot'): 0.0055248618784530384,\n",
       "             ('bohot', 'rash'): 0.07142857142857142,\n",
       "             ('rash', 'thaa'): 0.3333333333333333,\n",
       "             ('thaa', 'phir'): 0.14285714285714285,\n",
       "             ('phir', 'dinner'): 0.006172839506172839,\n",
       "             ('dinner', 'keya'): 0.06666666666666667,\n",
       "             ('keya', 'ghar'): 0.25,\n",
       "             ('ghar', 'gaay'): 0.006578947368421052,\n",
       "             ('gaay', 'aur'): 0.1,\n",
       "             ('aur', 'soogaau'): 0.00211864406779661,\n",
       "             ('soogaau', 'subah'): 1.0,\n",
       "             ('subah', '8'): 0.043478260869565216,\n",
       "             ('8', 'bjy'): 0.2,\n",
       "             ('bjy', 'utha'): 0.10714285714285714,\n",
       "             ('utha', 'fresh'): 0.037037037037037035,\n",
       "             ('fresh', 'hua'): 0.18518518518518517,\n",
       "             ('hua', 'nashta'): 0.03225806451612903,\n",
       "             ('nashta', 'kiya'): 0.35064935064935066,\n",
       "             ('kiya', 'aur'): 0.2752808988764045,\n",
       "             ('aur', 'university'): 0.01694915254237288,\n",
       "             ('university', 'k'): 0.0703125,\n",
       "             ('k', 'liye'): 0.15841584158415842,\n",
       "             ('liye', 'tyaar'): 0.017699115044247787,\n",
       "             ('tyaar', 'honay'): 0.14285714285714285,\n",
       "             ('honay', 'laga'): 0.14285714285714285,\n",
       "             ('laga', '9'): 0.05263157894736842,\n",
       "             ('9', 'bjy'): 0.11764705882352941,\n",
       "             ('bjy', 'apne'): 0.03571428571428571,\n",
       "             ('apne', 'bike'): 0.029411764705882353,\n",
       "             ('bike', 'pe'): 0.5,\n",
       "             ('pe', 'university'): 0.034482758620689655,\n",
       "             ('liye', 'nikal'): 0.08849557522123894,\n",
       "             ('nikal', 'gaya'): 0.4444444444444444,\n",
       "             ('gaya', 'aj'): 0.06432748538011696,\n",
       "             ('aj', 'friday'): 0.014705882352941176,\n",
       "             ('friday', 'ha'): 1.0,\n",
       "             ('ha', 'aur'): 0.25,\n",
       "             ('aur', 'aj'): 0.006355932203389831,\n",
       "             ('aj', 'mere'): 0.014705882352941176,\n",
       "             ('mere', 'sirf'): 0.125,\n",
       "             ('sirf', '2'): 0.18181818181818182,\n",
       "             ('2', 'classes'): 0.2,\n",
       "             ('classes', 'huti'): 0.020833333333333332,\n",
       "             ('huti', 'hain'): 1.0,\n",
       "             ('hain', 'university'): 0.10526315789473684,\n",
       "             ('university', 'ponch'): 0.0234375,\n",
       "             ('ponch', 'k'): 0.1,\n",
       "             ('k', 'classes'): 0.0049504950495049506,\n",
       "             ('classes', 'li'): 0.20833333333333334,\n",
       "             ('li', 'pehla'): 0.029411764705882353,\n",
       "             ('pehla', 'lecture'): 0.6666666666666666,\n",
       "             ('lecture', 'nlp'): 0.043478260869565216,\n",
       "             ('nlp', 'ka'): 0.38095238095238093,\n",
       "             ('ka', 'tha'): 0.012345679012345678,\n",
       "             ('tha', 'jis'): 0.0223463687150838,\n",
       "             ('jis', 'me'): 0.16666666666666666,\n",
       "             ('me', 'bhut'): 0.015873015873015872,\n",
       "             ('bhut', 'maza'): 1.0,\n",
       "             ('maza', 'aata'): 0.18181818181818182,\n",
       "             ('aata', 'ha'): 0.5,\n",
       "             ('ha', 'q'): 0.125,\n",
       "             ('q', 'k'): 0.6666666666666666,\n",
       "             ('k', 'hmaray'): 0.0049504950495049506,\n",
       "             ('hmaray', 'sir'): 1.0,\n",
       "             ('sir', 'kaafi'): 0.09090909090909091,\n",
       "             ('kaafi', 'achay'): 0.030303030303030304,\n",
       "             ('achay', 'hain'): 0.25,\n",
       "             ('hain', 'classes'): 0.05263157894736842,\n",
       "             ('classes', 'lene'): 0.041666666666666664,\n",
       "             ('lene', 'k'): 0.14285714285714285,\n",
       "             ('k', 'baad'): 0.22772277227722773,\n",
       "             ('baad', 'takreebn'): 0.004524886877828055,\n",
       "             ('takreebn', '12:50'): 0.3333333333333333,\n",
       "             ('12:50', 'pe'): 0.5,\n",
       "             ('pe', 'mein'): 0.034482758620689655,\n",
       "             ('mein', 'university'): 0.0055248618784530384,\n",
       "             ('university', 'se'): 0.0625,\n",
       "             ('se', 'ghar'): 0.014084507042253521,\n",
       "             ('ghar', 'k'): 0.03289473684210526,\n",
       "             ('liye', 'nikl'): 0.017699115044247787,\n",
       "             ('nikl', 'gaya'): 0.25,\n",
       "             ('gaya', 'aur'): 0.07602339181286549,\n",
       "             ('aur', 'alhamdulillah'): 0.00211864406779661,\n",
       "             ('alhamdulillah', 'jummah'): 1.0,\n",
       "             ('jummah', 'se'): 0.15384615384615385,\n",
       "             ('se', 'pehle'): 0.028169014084507043,\n",
       "             ('pehle', 'ghar'): 0.1111111111111111,\n",
       "             ('ghar', 'ponch'): 0.006578947368421052,\n",
       "             ('ponch', 'gaya'): 0.2,\n",
       "             ('gaya', 'jummah'): 0.011695906432748537,\n",
       "             ('jummah', 'ki'): 0.6153846153846154,\n",
       "             ('ki', 'tyaari'): 0.01272264631043257,\n",
       "             ('tyaari', 'ki'): 0.8333333333333334,\n",
       "             ('ki', 'aur'): 0.11195928753180662,\n",
       "             ('aur', 'apnay'): 0.00423728813559322,\n",
       "             ('apnay', 'bhai'): 0.08333333333333333,\n",
       "             ('bhai', 'k'): 0.1,\n",
       "             ('k', 'sath'): 0.14356435643564355,\n",
       "             ('sath', 'jummah'): 0.009708737864077669,\n",
       "             ('ki', 'namaz'): 0.12468193384223919,\n",
       "             ('namaz', 'k'): 0.05813953488372093,\n",
       "             ('liye', 'chala'): 0.02654867256637168,\n",
       "             ('chala', 'gaya'): 0.7142857142857143,\n",
       "             ('se', 'wpsi'): 0.004694835680751174,\n",
       "             ('wpsi', 'pe'): 1.0,\n",
       "             ('pe', 'gaoon'): 0.034482758620689655,\n",
       "             ('gaoon', 'ki'): 0.25,\n",
       "             ('ki', 'aj'): 0.010178117048346057,\n",
       "             ('aj', 'meri'): 0.07352941176470588,\n",
       "             ('meri', 'cousin'): 0.034482758620689655,\n",
       "             ('cousin', 'ki'): 1.0,\n",
       "             ('ki', 'mehndi'): 0.002544529262086514,\n",
       "             ('mehndi', 'thi'): 0.25,\n",
       "             ('thi', 'tu'): 0.010752688172043012,\n",
       "             ('tu', 'hmein'): 0.08333333333333333,\n",
       "             ('hmein', 'gaoon'): 1.0,\n",
       "             ('gaoon', 'k'): 0.5,\n",
       "             ('liye', 'niklna'): 0.008849557522123894,\n",
       "             ('niklna', 'tha'): 1.0,\n",
       "             ('tha', 'aur'): 0.027932960893854747,\n",
       "             ('aur', 'takreebn'): 0.00423728813559322,\n",
       "             ('takreebn', '3'): 0.3333333333333333,\n",
       "             ('3', 'bjy'): 0.0625,\n",
       "             ('bjy', 'tk'): 0.07142857142857142,\n",
       "             ('tk', 'hm'): 0.05555555555555555,\n",
       "             ('hm', 'log'): 0.5,\n",
       "             ('log', 'gaoon'): 0.5,\n",
       "             ('nikl', 'gaye'): 0.25,\n",
       "             ('gaye', '5'): 0.02040816326530612,\n",
       "             ('5', 'bjy'): 0.06666666666666667,\n",
       "             ('bjy', 'hm'): 0.03571428571428571,\n",
       "             ('gaoon', 'ponch'): 0.25,\n",
       "             ('ponch', 'gaye'): 0.1,\n",
       "             ('gaye', 'aur'): 0.10204081632653061,\n",
       "             ('aur', 'wahan'): 0.00847457627118644,\n",
       "             ('wahan', 'mene'): 0.034482758620689655,\n",
       "             ('mene', 'thori'): 0.07692307692307693,\n",
       "             ('thori', 'der'): 0.24,\n",
       "             ('der', 'rest'): 0.08695652173913043,\n",
       "             ('rest', 'kiya'): 0.46153846153846156,\n",
       "             ('takreebn', '7'): 0.3333333333333333,\n",
       "             ('7', 'bjy'): 0.21052631578947367,\n",
       "             ('tk', 'mehndi'): 0.05555555555555555,\n",
       "             ('mehndi', 'ka'): 0.25,\n",
       "             ('ka', 'function'): 0.00411522633744856,\n",
       "             ('function', 'start'): 0.5,\n",
       "             ('start', 'hu'): 0.0625,\n",
       "             ('hu', 'gya'): 0.25,\n",
       "             ('gya', 'tyaari'): 0.017857142857142856,\n",
       "             ('aur', 'mehndi'): 0.00211864406779661,\n",
       "             ('mehndi', 'k'): 0.25,\n",
       "             ('k', 'function'): 0.0049504950495049506,\n",
       "             ('function', 'pe'): 0.5,\n",
       "             ('pe', 'chala'): 0.034482758620689655,\n",
       "             ('wahan', 'sb'): 0.034482758620689655,\n",
       "             ('sb', 'cousins'): 0.5,\n",
       "             ('cousins', 'ikatay'): 0.3333333333333333,\n",
       "             ('ikatay', 'huway'): 1.0,\n",
       "             ('huway', 'aur'): 1.0,\n",
       "             ('aur', 'hm'): 0.00211864406779661,\n",
       "             ('hm', 'sb'): 0.25,\n",
       "             ('sb', 'ne'): 0.5,\n",
       "             ('ne', 'sai'): 0.009523809523809525,\n",
       "             ('sai', 'maza'): 0.07692307692307693,\n",
       "             ('maza', 'kiya'): 0.09090909090909091,\n",
       "             ('kiya', 'mehndi'): 0.0056179775280898875,\n",
       "             ('mehndi', 'se'): 0.25,\n",
       "             ('se', 'wapsi'): 0.004694835680751174,\n",
       "             ('wapsi', 'pe'): 0.3333333333333333,\n",
       "             ('pe', 'green'): 0.034482758620689655,\n",
       "             ('green', 'tea'): 1.0,\n",
       "             ('tea', 'pee'): 1.0,\n",
       "             ('pee', 'aur'): 0.5,\n",
       "             ('aur', 'kaafi'): 0.006355932203389831,\n",
       "             ('kaafi', 'thakawat'): 0.030303030303030304,\n",
       "             ('thakawat', 'ki'): 1.0,\n",
       "             ('ki', 'waja'): 0.010178117048346057,\n",
       "             ('waja', 'se'): 0.5555555555555556,\n",
       "             ('se', 'sonay'): 0.004694835680751174,\n",
       "             ('sonay', 'k'): 0.07692307692307693,\n",
       "             ('gaya', 'subah'): 0.017543859649122806,\n",
       "             ('subah', 'uth'): 0.043478260869565216,\n",
       "             ('uth', 'kar'): 0.4838709677419355,\n",
       "             ('kar', 'nashta'): 0.05,\n",
       "             ('nashta', 'tayar'): 0.03896103896103896,\n",
       "             ('tayar', 'kiya'): 0.04,\n",
       "             ('kiya', 'or'): 0.06179775280898876,\n",
       "             ('or', 'phir'): 0.208955223880597,\n",
       "             ('phir', 'kaya'): 0.0030864197530864196,\n",
       "             ('kaya', 'university'): 0.5,\n",
       "             ('liye', 'gaya'): 0.008849557522123894,\n",
       "             ('gaya', 'lekin'): 0.011695906432748537,\n",
       "             ('lekin', 'udher'): 0.022727272727272728,\n",
       "             ('udher', 'class'): 1.0,\n",
       "             ('class', 'cancel'): 0.033707865168539325,\n",
       "             ('cancel', 'thi'): 0.25,\n",
       "             ('thi', 'university'): 0.010752688172043012,\n",
       "             ('university', 'mai'): 0.0078125,\n",
       "             ('mai', 'dosto'): 0.012048192771084338,\n",
       "             ('dosto', 'k'): 0.06666666666666667,\n",
       "             ('sath', 'chess'): 0.009708737864077669,\n",
       "             ('chess', 'khaila'): 1.0,\n",
       "             ('khaila', 'sham'): 1.0,\n",
       "             ('sham', 'ko'): 0.7777777777777778,\n",
       "             ('ko', 'ghar'): 0.05084745762711865,\n",
       "             ('ghar', 'wapis'): 0.046052631578947366,\n",
       "             ('wapis', 'aya'): 0.13953488372093023,\n",
       "             ('aya', 'tu'): 0.03125,\n",
       "             ('tu', 'mehman'): 0.08333333333333333,\n",
       "             ('mehman', 'aye'): 0.25,\n",
       "             ('aye', 'howe'): 0.16666666666666666,\n",
       "             ('howe', 'thy'): 0.5,\n",
       "             ('thy', 'tu'): 0.125,\n",
       "             ('tu', 'sabse'): 0.08333333333333333,\n",
       "             ('sabse', 'mila'): 0.25,\n",
       "             ('mila', 'mehmano'): 0.07142857142857142,\n",
       "             ('mehmano', 'k'): 0.6666666666666666,\n",
       "             ('liye', 'khana'): 0.008849557522123894,\n",
       "             ('khana', 'pakaya'): 0.011764705882352941,\n",
       "             ('pakaya', 'raat'): 1.0,\n",
       "             ('raat', 'ko'): 0.4727272727272727,\n",
       "             ('ko', 'mehmano'): 0.00847457627118644,\n",
       "             ('sath', 'bohat'): 0.009708737864077669,\n",
       "             ('bohat', 'gup'): 0.05263157894736842,\n",
       "             ('gup', 'shup'): 0.8888888888888888,\n",
       "             ('shup', 'lagayi'): 0.3,\n",
       "             ('lagayi', 'or'): 0.2,\n",
       "             ('phir', 'sogaya'): 0.0030864197530864196,\n",
       "             ('sogaya', 'ajj'): 0.1,\n",
       "             ('ajj', 'subah'): 0.1,\n",
       "             ('kiya', 'nashty'): 0.0056179775280898875,\n",
       "             ('nashty', 'mai'): 0.3333333333333333,\n",
       "             ('mai', 'anda'): 0.012048192771084338,\n",
       "             ('anda', 'paratha'): 0.6666666666666666,\n",
       "             ('paratha', 'o'): 0.14285714285714285,\n",
       "             ('o', 'chaye'): 0.5,\n",
       "             ('chaye', 'thy'): 0.14285714285714285,\n",
       "             ('thy', 'nashty'): 0.125,\n",
       "             ('nashty', 'k'): 0.3333333333333333,\n",
       "             ('baad', 'islamabad'): 0.004524886877828055,\n",
       "             ('islamabad', 'janey'): 0.125,\n",
       "             ('janey', 'k'): 1.0,\n",
       "             ('liye', 'tayari'): 0.008849557522123894,\n",
       "             ('tayari', 'shuru'): 0.16666666666666666,\n",
       "             ('shuru', 'ki'): 0.25925925925925924,\n",
       "             ('ki', 'kapre'): 0.002544529262086514,\n",
       "             ('kapre', 'istri'): 1.0,\n",
       "             ('istri', 'kiye'): 0.6666666666666666,\n",
       "             ('kiye', 'or'): 0.06451612903225806,\n",
       "             ('or', 'nahaya'): 0.004975124378109453,\n",
       "             ('nahaya', '2'): 0.125,\n",
       "             ('2', 'baje'): 0.16,\n",
       "             ('baje', 'mamo'): 0.012345679012345678,\n",
       "             ('mamo', 'k'): 1.0,\n",
       "             ('k', 'ghar'): 0.009900990099009901,\n",
       "             ('ghar', 'pohanch'): 0.03289473684210526,\n",
       "             ('pohanch', 'kar'): 0.5,\n",
       "             ('kar', 'ali'): 0.007142857142857143,\n",
       "             ('ali', 'or'): 0.3333333333333333,\n",
       "             ('or', 'omar'): 0.004975124378109453,\n",
       "             ('omar', 'k'): 1.0,\n",
       "             ('sath', 'islamabad'): 0.009708737864077669,\n",
       "             ('islamabad', 'k'): 0.625,\n",
       "             ('liye', 'nikly'): 0.008849557522123894,\n",
       "             ('nikly', 'rasty'): 1.0,\n",
       "             ('rasty', 'mai'): 1.0,\n",
       "             ('mai', 'salar'): 0.012048192771084338,\n",
       "             ('salar', 'ko'): 1.0,\n",
       "             ('ko', 'pick'): 0.00847457627118644,\n",
       "             ('pick', 'kiya'): 1.0,\n",
       "             ('or', 'islamabad'): 0.004975124378109453,\n",
       "             ('liye', 'motorway'): 0.008849557522123894,\n",
       "             ('motorway', 'pr'): 0.5,\n",
       "             ('pr', 'gaye'): 0.16666666666666666,\n",
       "             ('gaye', '6'): 0.02040816326530612,\n",
       "             ('6', 'baje'): 0.3157894736842105,\n",
       "             ('baje', 'k'): 0.012345679012345678,\n",
       "             ('k', 'qareeb'): 0.009900990099009901,\n",
       "             ('qareeb', 'islamabad'): 0.2,\n",
       "             ('islamabad', 'pohanchy'): 0.125,\n",
       "             ('pohanchy', 'or'): 0.5,\n",
       "             ('or', 'salar'): 0.004975124378109453,\n",
       "             ('ko', 'newland'): 0.00847457627118644,\n",
       "             ('newland', 'school'): 1.0,\n",
       "             ('school', 'banigala'): 0.25,\n",
       "             ('banigala', 'drop'): 1.0,\n",
       "             ('drop', 'kiya'): 0.375,\n",
       "             ('or', 'hum'): 0.009950248756218905,\n",
       "             ('hum', 'i8'): 0.018518518518518517,\n",
       "             ('i8', 'markaz'): 0.3333333333333333,\n",
       "             ('markaz', 'hot'): 0.3333333333333333,\n",
       "             ('hot', 'and'): 1.0,\n",
       "             ('and', 'spicy'): 0.06666666666666667,\n",
       "             ('spicy', 'gaye'): 1.0,\n",
       "             ('gaye', 'waha'): 0.02040816326530612,\n",
       "             ('waha', 'or'): 0.14285714285714285,\n",
       "             ('or', 'malai'): 0.004975124378109453,\n",
       "             ('malai', 'roll'): 1.0,\n",
       "             ('roll', 'paratha'): 1.0,\n",
       "             ('paratha', 'khaya'): 0.14285714285714285,\n",
       "             ('khaya', 'i8'): 0.014705882352941176,\n",
       "             ('i8', 'k'): 0.3333333333333333,\n",
       "             ('baad', 'hum'): 0.03167420814479638,\n",
       "             ('hum', 'ghar'): 0.07407407407407407,\n",
       "             ('ghar', 'pohanchy'): 0.006578947368421052,\n",
       "             ('pohanchy', 'ghar'): 0.5,\n",
       "             ('ghar', 'pohanchny'): 0.006578947368421052,\n",
       "             ('pohanchny', 'k'): 1.0,\n",
       "             ('k', 'gainta'): 0.0049504950495049506,\n",
       "             ('gainta', 'baad'): 1.0,\n",
       "             ('baad', 'omer'): 0.004524886877828055,\n",
       "             ('omer', 'dental'): 0.25,\n",
       "             ('dental', 'clinic'): 1.0,\n",
       "             ('clinic', 'ja'): 0.5,\n",
       "             ('ja', 'raha'): 0.14285714285714285,\n",
       "             ('raha', 'tha'): 0.52,\n",
       "             ('tha', 'tu'): 0.027932960893854747,\n",
       "             ('tu', 'hum'): 0.08333333333333333,\n",
       "             ('hum', 'bhi'): 0.018518518518518517,\n",
       "             ('bhi', 'uske'): 0.01,\n",
       "             ('uske', 'sath'): 0.06818181818181818,\n",
       "             ('sath', 'chale'): 0.009708737864077669,\n",
       "             ('chale', 'gaye'): 0.625,\n",
       "             ('gaye', 'dental'): 0.02040816326530612,\n",
       "             ('clinic', 'se'): 0.5,\n",
       "             ('se', 'farigh'): 0.028169014084507043,\n",
       "             ('farigh', 'honey'): 0.1111111111111111,\n",
       "             ('honey', 'k'): 0.5,\n",
       "             ('hum', 'f6'): 0.018518518518518517,\n",
       "             ('f6', 'beverley'): 1.0,\n",
       "             ('beverley', 'center'): 1.0,\n",
       "             ('center', 'mai'): 1.0,\n",
       "             ('mai', 'annatummy'): 0.012048192771084338,\n",
       "             ('annatummy', 'restaurant'): 0.5,\n",
       "             ('restaurant', 'gaye'): 0.25,\n",
       "             ('gaye', 'or'): 0.04081632653061224,\n",
       "             ('or', 'waha'): 0.004975124378109453,\n",
       "             ('waha', 'pr'): 0.14285714285714285,\n",
       "             ('pr', 'beef'): 0.16666666666666666,\n",
       "             ('beef', 'burger'): 1.0,\n",
       "             ('burger', 'gaya'): 0.2,\n",
       "             ('gaya', 'annatummy'): 0.005847953216374269,\n",
       "             ('annatummy', 'ka'): 0.5,\n",
       "             ('ka', 'surgeon'): 0.00411522633744856,\n",
       "             ('surgeon', '20'): 0.5,\n",
       "             ('20', 'burger'): 0.5,\n",
       "             ('burger', 'bohat'): 0.2,\n",
       "             ('bohat', 'delicious'): 0.05263157894736842,\n",
       "             ('delicious', 'hai'): 1.0,\n",
       "             ('hai', 'burger'): 0.013333333333333334,\n",
       "             ('burger', 'khaney'): 0.2,\n",
       "             ('khaney', 'k'): 1.0,\n",
       "             ('baad', 'chaye'): 0.013574660633484163,\n",
       "             ('chaye', 'pi'): 0.14285714285714285,\n",
       "             ('pi', 'or'): 0.08333333333333333,\n",
       "             ('or', '12'): 0.009950248756218905,\n",
       "             ('12', 'baje'): 0.23076923076923078,\n",
       "             ('baje', 'ghar'): 0.037037037037037035,\n",
       "             ('ghar', 'pohancha'): 0.013157894736842105,\n",
       "             ('pohancha', 'ghar'): 0.5,\n",
       "             ('kar', 'toda'): 0.007142857142857143,\n",
       "             ('toda', 'sa'): 1.0,\n",
       "             ('sa', 'insta'): 0.03571428571428571,\n",
       "             ('insta', 'scroll'): 0.4,\n",
       "             ('scroll', 'kiya'): 0.3125,\n",
       "             ('or', 'sogaya'): 0.004975124378109453,\n",
       "             ('sogaya', 'aaj'): 0.2,\n",
       "             ('aaj', 'mai'): 0.0449438202247191,\n",
       "             ('mai', 'subah'): 0.060240963855421686,\n",
       "             ('8', 'bajay'): 0.4,\n",
       "             ('bajay', 'utha'): 0.12658227848101267,\n",
       "             ('utha', 'phehle'): 0.018518518518518517,\n",
       "             ('phehle', 'mai'): 0.5,\n",
       "             ('mai', 'ne'): 0.03614457831325301,\n",
       "             ('ne', 'nahsta'): 0.009523809523809525,\n",
       "             ('nahsta', 'tayar'): 1.0,\n",
       "             ('tayar', 'kia'): 0.04,\n",
       "             ('kia', 'or'): 0.13924050632911392,\n",
       "             ('phir', 'naha'): 0.0030864197530864196,\n",
       "             ('naha', 'tayar'): 0.25,\n",
       "             ('tayar', 'ho'): 0.16,\n",
       "             ('ho', 'k'): 0.012195121951219513,\n",
       "             ('k', 'university'): 0.009900990099009901,\n",
       "             ('gaya', 'university'): 0.023391812865497075,\n",
       "             ('university', '10:10'): 0.0078125,\n",
       "             ('10:10', 'tak'): 1.0,\n",
       "             ('tak', 'poncha'): 0.012195121951219513,\n",
       "             ('poncha', '10'): 0.2,\n",
       "             ('10', 'min'): 0.037037037037037035,\n",
       "             ('min', 'late'): 0.5,\n",
       "             ('late', 'phehle'): 0.045454545454545456,\n",
       "             ('phehle', 'class'): 0.5,\n",
       "             ('class', 'cloud'): 0.011235955056179775,\n",
       "             ('cloud', 'computing'): 1.0,\n",
       "             ('computing', 'ki'): 0.6666666666666666,\n",
       "             ('ki', 'li'): 0.002544529262086514,\n",
       "             ('li', 'aur'): 0.29411764705882354,\n",
       "             ('aur', 'phir'): 0.11652542372881355,\n",
       "             ('phir', '11:30'): 0.0030864197530864196,\n",
       "             ('11:30', 'ko'): 0.058823529411764705,\n",
       "             ('ko', 'nlp'): 0.00847457627118644,\n",
       "             ('nlp', 'ki'): 0.2857142857142857,\n",
       "             ('ki', 'classes'): 0.017811704834605598,\n",
       "             ('classes', 'k'): 0.041666666666666664,\n",
       "             ('k', 'bad'): 0.039603960396039604,\n",
       "             ('bad', 'cafe'): 0.05263157894736842,\n",
       "             ('cafe', 'chala'): 0.13793103448275862,\n",
       "             ('gaya', 'dosto'): 0.005847953216374269,\n",
       "             ('dosto', 'se'): 0.06666666666666667,\n",
       "             ('se', 'mila'): 0.023474178403755867,\n",
       "             ('mila', 'or'): 0.07142857142857142,\n",
       "             ('phir', 'jummah'): 0.006172839506172839,\n",
       "             ('jummah', 'k'): 0.15384615384615385,\n",
       "             ('gaya', '1:30'): 0.005847953216374269,\n",
       "             ('1:30', 'ko'): 1.0,\n",
       "             ('ko', 'jummah'): 0.00847457627118644,\n",
       "             ('jummah', 'parha'): 0.07692307692307693,\n",
       "             ('parha', 'or'): 0.08333333333333333,\n",
       "             ('phir', 'dubara'): 0.0030864197530864196,\n",
       "             ('dubara', 'cafe'): 0.2,\n",
       "             ('cafe', 'aa'): 0.034482758620689655,\n",
       "             ('aa', 'k'): 0.13333333333333333,\n",
       "             ('k', 'khana'): 0.0049504950495049506,\n",
       "             ('khana', 'khaya'): 0.4588235294117647,\n",
       "             ('khaya', 'khana'): 0.029411764705882353,\n",
       "             ('khana', 'khany'): 0.03529411764705882,\n",
       "             ('khany', 'k'): 0.125,\n",
       "             ('bad', 'mai'): 0.10526315789473684,\n",
       "             ('mai', 'ghar'): 0.024096385542168676,\n",
       "             ('ghar', 'aaya'): 0.03289473684210526,\n",
       "             ('aaya', 'or'): 0.06666666666666667,\n",
       "             ('or', 'saman'): 0.004975124378109453,\n",
       "             ('saman', 'pack'): 0.16666666666666666,\n",
       "             ('pack', 'kia'): 0.25,\n",
       "             ('kia', 'kyun'): 0.012658227848101266,\n",
       "             ('kyun', 'k'): 0.2857142857142857,\n",
       "             ('k', 'mai'): 0.0049504950495049506,\n",
       "             ('ne', 'aaj'): 0.009523809523809525,\n",
       "             ('aaj', 'jana'): 0.011235955056179775,\n",
       "             ('jana', 'tha'): 0.6923076923076923,\n",
       "             ('tha', 'ghr'): 0.00558659217877095,\n",
       "             ('ghr', 'home'): 0.08333333333333333,\n",
       "             ('home', 'town'): 0.4,\n",
       "             ('town', 'bags'): 0.5,\n",
       "             ('bags', 'tayar'): 1.0,\n",
       "             ('tayar', 'kiye'): 0.04,\n",
       "             ('or', 'nikal'): 0.004975124378109453,\n",
       "             ('nikal', 'gare'): 0.037037037037037035,\n",
       "             ('gare', 'book'): 1.0,\n",
       "             ('book', 'ki'): 0.1111111111111111,\n",
       "             ('aur', 'chaly'): 0.00211864406779661,\n",
       "             ('chaly', 'gayae'): 0.25,\n",
       "             ('gayae', 'daewoo'): 0.3333333333333333,\n",
       "             ('daewoo', 'faizabad'): 0.5,\n",
       "             ('faizabad', 'waha'): 1.0,\n",
       "             ('waha', 'tore'): 0.14285714285714285,\n",
       "             ('tore', 'dhair'): 0.5,\n",
       "             ('dhair', 'intizar'): 0.3333333333333333,\n",
       "             ('intizar', 'kia'): 0.5,\n",
       "             ('kia', 'aur'): 0.189873417721519,\n",
       "             ('aur', 'sath'): 0.012711864406779662,\n",
       "             ('sath', 'mai'): 0.009708737864077669,\n",
       "             ('mai', 'asar'): 0.012048192771084338,\n",
       "             ('asar', 'ki'): 0.7142857142857143,\n",
       "             ('namaz', 'parhe'): 0.03488372093023256,\n",
       "             ('parhe', 'itne'): 0.3333333333333333,\n",
       "             ('itne', 'dhair'): 0.5,\n",
       "             ('dhair', 'mai'): 0.3333333333333333,\n",
       "             ('mai', 'bus'): 0.024096385542168676,\n",
       "             ('bus', 'ka'): 0.125,\n",
       "             ('ka', 'time'): 0.06995884773662552,\n",
       "             ('time', 'hogaya'): 0.08163265306122448,\n",
       "             ('hogaya', '4:30'): 0.1,\n",
       "             ('4:30', 'ko'): 0.5,\n",
       "             ('ko', 'bus'): 0.025423728813559324,\n",
       "             ('bus', 'nikl'): 0.03125,\n",
       "             ('nikl', 'gayee'): 0.25,\n",
       "             ('gayee', 'aue'): 0.5,\n",
       "             ('aue', '20'): 1.0,\n",
       "             ('20', 'min'): 0.5,\n",
       "             ('min', 'mai'): 0.25,\n",
       "             ('mai', 'daewoo'): 0.012048192771084338,\n",
       "             ('daewoo', 'main'): 0.5,\n",
       "             ('main', 'stop'): 0.014705882352941176,\n",
       "             ('stop', 'mai'): 0.14285714285714285,\n",
       "             ('mai', 'ponch'): 0.012048192771084338,\n",
       "             ('ponch', 'gayae'): 0.1,\n",
       "             ('gayae', 'wahan'): 0.3333333333333333,\n",
       "             ('wahan', 'phr'): 0.034482758620689655,\n",
       "             ('phr', 'tora'): 0.07142857142857142,\n",
       "             ('tora', 'sa'): 0.6666666666666666,\n",
       "             ('sa', 'intizar'): 0.03571428571428571,\n",
       "             ('phir', 'hus'): 0.0030864197530864196,\n",
       "             ('hus', 'nikl'): 1.0,\n",
       "             ('nikl', 'gayae'): 0.25,\n",
       "             ('gayae', '5'): 0.3333333333333333,\n",
       "             ('5', 'bajay'): 0.26666666666666666,\n",
       "             ('bajay', 'rasty'): 0.012658227848101266,\n",
       "             ('ne', 'maghrib'): 0.009523809523809525,\n",
       "             ('maghrib', 'ki'): 0.4375,\n",
       "             ('parhe', 'taqreeban'): 0.3333333333333333,\n",
       "             ('taqreeban', '2'): 0.16666666666666666,\n",
       "             ('2', 'ghanty'): 0.04,\n",
       "             ('ghanty', 'safar'): 1.0,\n",
       "             ('safar', 'k'): 0.3333333333333333,\n",
       "             ('bad', 'hum'): 0.05263157894736842,\n",
       "             ('hum', 'ponch'): 0.018518518518518517,\n",
       "             ('ponch', 'gayee'): 0.1,\n",
       "             ('gayee', 'batkhela'): 0.5,\n",
       "             ('batkhela', 'jo'): 1.0,\n",
       "             ('jo', 'mera'): 0.02702702702702703,\n",
       "             ('mera', 'home'): 0.09090909090909091,\n",
       "             ('town', 'hai'): 0.5,\n",
       "             ('hai', 'waha'): 0.013333333333333334,\n",
       "             ('waha', 'par'): 0.2857142857142857,\n",
       "             ('par', 'bhai'): 0.022222222222222223,\n",
       "             ('bhai', 'aaya'): 0.1,\n",
       "             ('aaya', 'tehra'): 0.06666666666666667,\n",
       "             ('tehra', 'tha'): 1.0,\n",
       "             ('tha', 'intizar'): 0.00558659217877095,\n",
       "             ('intizar', 'kr'): 0.25,\n",
       "             ('kr', 'raha'): 0.016129032258064516,\n",
       "             ('tha', 'phir'): 0.0335195530726257,\n",
       "             ('ghar', 'ponchy'): 0.006578947368421052,\n",
       "             ('ponchy', 'ghar'): 0.5,\n",
       "             ('ghar', 'aa'): 0.06578947368421052,\n",
       "             ('aa', 'kar'): 0.08888888888888889,\n",
       "             ('kar', 'phehly'): 0.007142857142857143,\n",
       "             ('phehly', 'ammi'): 1.0,\n",
       "             ('ammi', 'abbu'): 0.5,\n",
       "             ('abbu', 'se'): 1.0,\n",
       "             ('se', 'mily'): 0.004694835680751174,\n",
       "             ('mily', 'or'): 1.0,\n",
       "             ('phir', 'khana'): 0.012345679012345678,\n",
       "             ('khaya', 'us'): 0.029411764705882353,\n",
       "             ('us', 'k'): 0.3157894736842105,\n",
       "             ('bad', 'tore'): 0.05263157894736842,\n",
       "             ('tore', 'se'): 0.5,\n",
       "             ('se', 'walk'): 0.004694835680751174,\n",
       "             ('walk', 'ki'): 0.125,\n",
       "             ('ki', 'or'): 0.04071246819338423,\n",
       "             ('phir', 'isha'): 0.0030864197530864196,\n",
       "             ('isha', 'ki'): 0.6428571428571429,\n",
       "             ('parhe', 'phir'): 0.3333333333333333,\n",
       "             ('phir', 'family'): 0.0030864197530864196,\n",
       "             ('family', 'k'): 0.2727272727272727,\n",
       "             ('sath', 'tora'): 0.009708737864077669,\n",
       "             ('sa', 'waqt'): 0.07142857142857142,\n",
       "             ('waqt', 'guzara'): 0.22727272727272727,\n",
       "             ('guzara', 'aur'): 0.25,\n",
       "             ('phir', 'taqreeban'): 0.0030864197530864196,\n",
       "             ('taqreeban', '12'): 0.16666666666666666,\n",
       "             ('12', 'bajay'): 0.38461538461538464,\n",
       "             ('bajay', 'so'): 0.0379746835443038,\n",
       "             ('so', 'gaya'): 0.37037037037037035,\n",
       "             ('gaya', 'aaj'): 0.04678362573099415,\n",
       "             ('aaj', 'mein'): 0.10112359550561797,\n",
       "             ('mein', 'subh'): 0.016574585635359115,\n",
       "             ('subh', '8:15'): 0.3333333333333333,\n",
       "             ('8:15', 'pe'): 1.0,\n",
       "             ('pe', 'uthi'): 0.13793103448275862,\n",
       "             ('uthi', 'aur'): 0.3181818181818182,\n",
       "             ('aur', 'tyar'): 0.01059322033898305,\n",
       "             ('tyar', 'hu'): 0.08333333333333333,\n",
       "             ('hu', 'kr'): 0.5,\n",
       "             ('kr', 'university'): 0.03225806451612903,\n",
       "             ('university', 'ke'): 0.125,\n",
       "             ('ke', 'lya'): 0.01524390243902439,\n",
       "             ('lya', 'nikal'): 0.5,\n",
       "             ('nikal', 'gayi'): 0.1111111111111111,\n",
       "             ('gayi', 'aur'): 0.24528301886792453,\n",
       "             ('aur', '9:30'): 0.00211864406779661,\n",
       "             ('9:30', 'tk'): 0.5,\n",
       "             ('tk', 'university'): 0.1111111111111111,\n",
       "             ('university', 'pohunch'): 0.015625,\n",
       "             ('pohunch', 'gayi'): 0.6666666666666666,\n",
       "             ('gayi', 'university'): 0.03773584905660377,\n",
       "             ('university', 'pohunchte'): 0.0078125,\n",
       "             ('pohunchte', 'hi'): 1.0,\n",
       "             ('hi', 'sab'): 0.023809523809523808,\n",
       "             ('sab', 'se'): 0.18421052631578946,\n",
       "             ('se', 'phela'): 0.004694835680751174,\n",
       "             ('phela', 'apna'): 0.5,\n",
       "             ('apna', 'doston'): 0.10526315789473684,\n",
       "             ('doston', 'se'): 0.225,\n",
       "             ('se', 'milli'): 0.004694835680751174,\n",
       "             ('milli', 'aur'): 1.0,\n",
       "             ('aur', 'thori'): 0.00847457627118644,\n",
       "             ('thori', 'dair'): 0.24,\n",
       "             ('dair', 'unke'): 0.030303030303030304,\n",
       "             ('unke', 'sath'): 0.8,\n",
       "             ('sath', 'beth'): 0.019417475728155338,\n",
       "             ('beth', 'gayi'): 0.07692307692307693,\n",
       "             ('gayi', 'aaj'): 0.09433962264150944,\n",
       "             ('aaj', 'hamara'): 0.011235955056179775,\n",
       "             ('hamara', 'dip'): 0.25,\n",
       "             ('dip', 'ka'): 0.4166666666666667,\n",
       "             ('ka', 'quiz'): 0.02880658436213992,\n",
       "             ('quiz', 'tha'): 0.08823529411764706,\n",
       "             ('tu', 'mein'): 0.25,\n",
       "             ('mein', 'ne'): 0.11602209944751381,\n",
       "             ('ne', 'udhr'): 0.009523809523809525,\n",
       "             ('udhr', 'beth'): 0.5,\n",
       "             ('beth', 'kr'): 0.19230769230769232,\n",
       "             ('kr', 'quiz'): 0.016129032258064516,\n",
       "             ('quiz', 'tyar'): 0.08823529411764706,\n",
       "             ('tyar', 'kya'): 0.16666666666666666,\n",
       "             ('kya', 'quiz'): 0.045454545454545456,\n",
       "             ('tyar', 'krne'): 0.08333333333333333,\n",
       "             ('krne', 'ke'): 0.25,\n",
       "             ('ke', 'bd'): 0.01524390243902439,\n",
       "             ('bd', 'nashta'): 0.07142857142857142,\n",
       "             ('nashta', 'kya'): 0.025974025974025976,\n",
       "             ('kya', 'aur'): 0.13636363636363635,\n",
       "             ('wahan', 'beth'): 0.034482758620689655,\n",
       "             ('kr', 'batein'): 0.016129032258064516,\n",
       "             ('batein', 'ki'): 0.4,\n",
       "             ('aur', 'uske'): 0.019067796610169493,\n",
       "             ('uske', 'bd'): 0.18181818181818182,\n",
       "             ('bd', 'mein'): 0.5714285714285714,\n",
       "             ('mein', 'class'): 0.0055248618784530384,\n",
       "             ('class', 'lena'): 0.0449438202247191,\n",
       "             ('lena', 'chali'): 0.2857142857142857,\n",
       "             ('chali', 'gaye'): 0.14285714285714285,\n",
       "             ('gaye', 'class'): 0.02040816326530612,\n",
       "             ('class', 'se'): 0.011235955056179775,\n",
       "             ('se', 'free'): 0.046948356807511735,\n",
       "             ('free', 'hukr'): 0.17391304347826086,\n",
       "             ('hukr', 'hamara'): 0.2,\n",
       "             ('hamara', '1'): 0.25,\n",
       "             ('1', 'hour'): 0.041666666666666664,\n",
       "             ('hour', 'ka'): 0.5,\n",
       "             ('ka', 'break'): 0.012345679012345678,\n",
       "             ('break', 'tha'): 0.1111111111111111,\n",
       "             ('jis', 'mein'): 0.08333333333333333,\n",
       "             ('mein', 'mera'): 0.0055248618784530384,\n",
       "             ('mera', 'doston'): 0.09090909090909091,\n",
       "             ('doston', 'ne'): 0.05,\n",
       "             ('ne', 'aur'): 0.009523809523809525,\n",
       "             ('aur', 'mein'): 0.00847457627118644,\n",
       "             ('ne', 'pdc'): 0.01904761904761905,\n",
       "             ('pdc', 'ka'): 0.2,\n",
       "             ('kya', 'uske'): 0.045454545454545456,\n",
       "             ('bd', '2:30'): 0.07142857142857142,\n",
       "             ('2:30', 'hum'): 0.1,\n",
       "             ('hum', 'apni'): 0.05555555555555555,\n",
       "             ('apni', 'pdc'): 0.030303030303030304,\n",
       "             ('pdc', 'ki'): 0.4,\n",
       "             ('ki', 'class'): 0.05343511450381679,\n",
       "             ('lena', 'chale'): 0.2857142857142857,\n",
       "             ('gaye', 'pr'): 0.02040816326530612,\n",
       "             ('pr', 'usmein'): 0.16666666666666666,\n",
       "             ('usmein', 'quiz'): 1.0,\n",
       "             ('quiz', 'nhi'): 0.029411764705882353,\n",
       "             ('nhi', 'hua'): 0.07692307692307693,\n",
       "             ('hua', '5:15'): 0.03225806451612903,\n",
       "             ('5:15', 'tk'): 0.3333333333333333,\n",
       "             ('tk', 'hum'): 0.1111111111111111,\n",
       "             ('apni', 'classes'): 0.06060606060606061,\n",
       "             ('classes', 'se'): 0.08333333333333333,\n",
       "             ('free', 'hugye'): 0.043478260869565216,\n",
       "             ('hugye', 'aur'): 1.0,\n",
       "             ('mein', 'basket'): 0.0055248618784530384,\n",
       "             ('basket', 'ball'): 1.0,\n",
       "             ('ball', 'court'): 1.0,\n",
       "             ('court', 'chali'): 0.5,\n",
       "             ('gaye', 'jahan'): 0.02040816326530612,\n",
       "             ('jahan', 'beth'): 1.0,\n",
       "             ('beth', 'ke'): 0.07692307692307693,\n",
       "             ('ke', 'mein'): 0.006097560975609756,\n",
       "             ('ne', 'book'): 0.009523809523809525,\n",
       "             ('book', 'prhi'): 0.1111111111111111,\n",
       "             ('prhi', 'uske'): 0.25,\n",
       "             ('bd', 'mujhe'): 0.07142857142857142,\n",
       "             ('mujhe', 'lena'): 0.038461538461538464,\n",
       "             ('lena', 'a'): 0.14285714285714285,\n",
       "             ('a', 'gye'): 0.034482758620689655,\n",
       "             ('gye', 'aur'): 1.0,\n",
       "             ('mein', '7:30'): 0.011049723756906077,\n",
       "             ('7:30', 'tk'): 0.08333333333333333,\n",
       "             ('tk', 'ghar'): 0.1111111111111111,\n",
       "             ('ghar', 'pohunch'): 0.006578947368421052,\n",
       "             ('gayi', 'ghar'): 0.018867924528301886,\n",
       "             ('ghar', 'pohunchna'): 0.006578947368421052,\n",
       "             ('pohunchna', 'ke'): 1.0,\n",
       "             ('ne', 'khana'): 0.047619047619047616,\n",
       "             ('khaya', 'chai'): 0.029411764705882353,\n",
       "             ('chai', 'pi'): 0.2222222222222222,\n",
       "             ('pi', 'aur'): 0.25,\n",
       "             ('sath', 'nascon'): 0.019417475728155338,\n",
       "             ('nascon', 'ka'): 0.4,\n",
       "             ('ka', 'kaam'): 0.0823045267489712,\n",
       "             ('kaam', 'kiya'): 0.13829787234042554,\n",
       "             ('kiya', 'sab'): 0.0056179775280898875,\n",
       "             ('sab', 'selected'): 0.02631578947368421,\n",
       "             ('selected', 'candidates'): 1.0,\n",
       "             ('candidates', 'ko'): 1.0,\n",
       "             ('ko', 'email'): 0.00847457627118644,\n",
       "             ('email', 'ki'): 1.0,\n",
       "             ('ki', 'nascon'): 0.002544529262086514,\n",
       "             ('kaam', 'complete'): 0.031914893617021274,\n",
       "             ('complete', 'kr'): 0.1,\n",
       "             ('kr', 'ke'): 0.016129032258064516,\n",
       "             ('ke', 'thori'): 0.003048780487804878,\n",
       "             ('dair', 'youtube'): 0.06060606060606061,\n",
       "             ('youtube', 'dekha'): 0.3333333333333333,\n",
       "             ('dekha', 'aur'): 0.35714285714285715,\n",
       "             ('mein', 'so'): 0.011049723756906077,\n",
       "             ('so', 'gayi'): 0.14814814814814814,\n",
       "             ('subh', '10:30'): 0.3333333333333333,\n",
       "             ('10:30', 'pe'): 0.5,\n",
       "             ('uthi', 'nashta'): 0.13636363636363635,\n",
       "             ('aur', 'apna'): 0.00423728813559322,\n",
       "             ('apna', 'room'): 0.05263157894736842,\n",
       "             ('room', 'thora'): 0.058823529411764705,\n",
       "             ('thora', 'organize'): 0.03571428571428571,\n",
       "             ('organize', 'kiya'): 0.5,\n",
       "             ('kiya', 'thori'): 0.016853932584269662,\n",
       "             ('dair', 'tv'): 0.06060606060606061,\n",
       "             ('tv', 'dekha'): 0.8333333333333334,\n",
       "             ('sath', 'chai'): 0.038834951456310676,\n",
       "             ('pi', 'uske'): 0.16666666666666666,\n",
       "             ('ne', 'mama'): 0.009523809523809525,\n",
       "             ('mama', 'ke'): 0.14285714285714285,\n",
       "             ('ke', 'sath'): 0.07926829268292683,\n",
       "             ('sath', 'ghar'): 0.009708737864077669,\n",
       "             ('ghar', 'ke'): 0.02631578947368421,\n",
       "             ('ke', 'kamon'): 0.003048780487804878,\n",
       "             ('kamon', 'mein'): 0.6666666666666666,\n",
       "             ('mein', 'unki'): 0.0055248618784530384,\n",
       "             ('unki', 'help'): 1.0,\n",
       "             ('help', 'krwai'): 0.6666666666666666,\n",
       "             ('krwai', 'aur'): 1.0,\n",
       "             ('aur', '2:00'): 0.00211864406779661,\n",
       "             ('2:00', 'tk'): 0.3333333333333333,\n",
       "             ('tk', 'free'): 0.16666666666666666,\n",
       "             ('hukr', 'university'): 0.4,\n",
       "             ('university', 'ka'): 0.1328125,\n",
       "             ('kaam', 'shuru'): 0.06382978723404255,\n",
       "             ('shuru', 'kiya'): 0.14814814814814814,\n",
       "             ('kiya', 'usi'): 0.0056179775280898875,\n",
       "             ('usi', 'ke'): 0.3333333333333333,\n",
       "             ('sath', 'sath'): 0.02912621359223301,\n",
       "             ('kaam', 'bhi'): 0.06382978723404255,\n",
       "             ('bhi', 'complete'): 0.01,\n",
       "             ('complete', 'kiya'): 0.3,\n",
       "             ('aur', '5:00'): 0.00211864406779661,\n",
       "             ('5:00', 'tk'): 0.25,\n",
       "             ('free', 'hugyi'): 0.08695652173913043,\n",
       "             ('hugyi', 'phir'): 0.5,\n",
       "             ('phir', 'maghrib'): 0.0030864197530864196,\n",
       "             ('namaz', 'parhi'): 0.36046511627906974,\n",
       "             ('parhi', 'aur'): 0.3181818181818182,\n",
       "             ('aur', '6:00'): 0.00423728813559322,\n",
       "             ('6:00', 'tk'): 0.3333333333333333,\n",
       "             ('tk', 'sab'): 0.05555555555555555,\n",
       "             ('sab', 'ke'): 0.07894736842105263,\n",
       "             ('lya', 'chai'): 0.16666666666666666,\n",
       "             ('chai', 'banai'): 0.07407407407407407,\n",
       "             ('banai', 'uss'): 0.2,\n",
       "             ('uss', 'ke'): 0.5714285714285714,\n",
       "             ('ne', 'thori'): 0.02857142857142857,\n",
       "             ('dair', 'break'): 0.06060606060606061,\n",
       "             ('break', 'liya'): 0.1111111111111111,\n",
       "             ('liya', 'aur'): 0.1,\n",
       "             ('phir', 'se'): 0.018518518518518517,\n",
       "             ('se', 'nascon'): 0.004694835680751174,\n",
       "             ('kiya', 'uske'): 0.011235955056179775,\n",
       "             ('bd', 'dinner'): 0.07142857142857142,\n",
       "             ('dinner', 'mein'): 0.06666666666666667,\n",
       "             ('mein', 'mama'): 0.0055248618784530384,\n",
       "             ('mama', 'ki'): 0.14285714285714285,\n",
       "             ('ki', 'help'): 0.002544529262086514,\n",
       "             ('aur', '9:00'): 0.00211864406779661,\n",
       "             ('9:00', 'tk'): 0.5,\n",
       "             ('tk', 'mein'): 0.05555555555555555,\n",
       "             ('khana', 'kha'): 0.047058823529411764,\n",
       "             ('kha', 'liya'): 0.3,\n",
       "             ('liya', '9:30'): 0.03333333333333333,\n",
       "             ('9:30', 'aik'): 0.25,\n",
       "             ('aik', 'meeting'): 0.06666666666666667,\n",
       "             ('meeting', 'attend'): 0.3333333333333333,\n",
       "             ('attend', 'ki'): 0.5652173913043478,\n",
       "             ('aur', 'us'): 0.01059322033898305,\n",
       "             ('us', 'se'): 0.05263157894736842,\n",
       "             ('free', 'hu'): 0.043478260869565216,\n",
       "             ('kr', 'nlp'): 0.016129032258064516,\n",
       "             ('ka', 'home'): 0.012345679012345678,\n",
       "             ('home', 'task'): 0.4,\n",
       "             ('task', 'kiya'): 0.25,\n",
       "             ('kiya', 'us'): 0.011235955056179775,\n",
       "             ('us', 'ke'): 0.07894736842105263,\n",
       "             ('break', 'li'): 0.05555555555555555,\n",
       "             ('phir', 'dip'): 0.0030864197530864196,\n",
       "             ('dip', 'ke'): 0.16666666666666666,\n",
       "             ('ke', 'quiz'): 0.003048780487804878,\n",
       "             ('quiz', 'ki'): 0.29411764705882354,\n",
       "             ('ki', 'tiyari'): 0.01272264631043257,\n",
       "             ('tiyari', 'ki'): 0.6,\n",
       "             ('ki', 'quiz'): 0.005089058524173028,\n",
       "             ('tiyari', 'krne'): 0.2,\n",
       "             ('ne', 'namaz'): 0.01904761904761905,\n",
       "             ('namaz', 'prhi'): 0.03488372093023256,\n",
       "             ('prhi', 'phir'): 0.25,\n",
       "             ('phir', 'youtube'): 0.006172839506172839,\n",
       "             ('youtube', 'dekhte'): 0.08333333333333333,\n",
       "             ('dekhte', 'dekhte'): 0.5,\n",
       "             ('dekhte', 'so'): 0.5,\n",
       "             ('subh', '8:30'): 0.3333333333333333,\n",
       "             ('8:30', 'pe'): 0.15384615384615385,\n",
       "             ('tyar', 'hukr'): 0.08333333333333333,\n",
       "             ('gayi', '9:30'): 0.018867924528301886,\n",
       "             ('university', 'pohunchi'): 0.0078125,\n",
       "             ('pohunchi', 'aur'): 0.5,\n",
       "             ('aur', 'kuch'): 0.02754237288135593,\n",
       "             ('kuch', 'dair'): 0.033707865168539325,\n",
       "             ('dair', 'library'): 0.030303030303030304,\n",
       "             ('library', 'beth'): 0.07692307692307693,\n",
       "             ('kr', 'apna'): 0.016129032258064516,\n",
       "             ('apna', 'kaam'): 0.15789473684210525,\n",
       "             ('kiya', 'kuch'): 0.011235955056179775,\n",
       "             ('kuch', 'time'): 0.056179775280898875,\n",
       "             ('time', 'bd'): 0.02040816326530612,\n",
       "             ('bd', 'meri'): 0.07142857142857142,\n",
       "             ('meri', 'dost'): 0.13793103448275862,\n",
       "             ('dost', 'library'): 0.02127659574468085,\n",
       "             ('library', 'a'): 0.07692307692307693,\n",
       "             ('a', 'gyi'): 0.10344827586206896,\n",
       "             ('gyi', 'aur'): 0.25,\n",
       "             ('uske', 'mein'): 0.022727272727272728,\n",
       "             ('mein', 'cafe'): 0.011049723756906077,\n",
       "             ('cafe', 'chali'): 0.034482758620689655,\n",
       "             ('chali', 'gayi'): 0.6428571428571429,\n",
       "             ('gayi', 'jahan'): 0.018867924528301886,\n",
       "             ('ke', 'hum'): 0.003048780487804878,\n",
       "             ('hum', 'ne'): 0.2962962962962963,\n",
       "             ('ne', 'batein'): 0.009523809523809525,\n",
       "             ('ki', '11:30'): 0.007633587786259542,\n",
       "             ('11:30', 'tk'): 0.058823529411764705,\n",
       "             ('apni', 'dip'): 0.030303030303030304,\n",
       "             ('dip', 'ki'): 0.25,\n",
       "             ('gaye', '1:00'): 0.02040816326530612,\n",
       "             ('1:00', 'tk'): 0.16666666666666666,\n",
       "             ('hukr', 'library'): 0.2,\n",
       "             ('library', 'mein'): 0.23076923076923078,\n",
       "             ('mein', 'beth'): 0.03314917127071823,\n",
       "             ('kr', 'ann'): 0.03225806451612903,\n",
       "             ('ann', 'ka'): 0.2727272727272727,\n",
       "             ('ka', 'parha'): 0.00411522633744856,\n",
       "             ('parha', 'aur'): 0.25,\n",
       "             ('khana', 'khane'): 0.047058823529411764,\n",
       "             ('khane', 'ke'): 0.42857142857142855,\n",
       "             ('lya', 'cafe'): 0.16666666666666666,\n",
       "             ('cafe', 'chale'): 0.034482758620689655,\n",
       "             ('gaye', 'uske'): 0.02040816326530612,\n",
       "             ('prhi', 'aur'): 0.25,\n",
       "             ('aur', '2:30'): 0.00423728813559322,\n",
       "             ('2:30', 'pdc'): 0.1,\n",
       "             ('gayi', '5:15'): 0.018867924528301886,\n",
       "             ('tk', 'apni'): 0.05555555555555555,\n",
       "             ('apni', 'sari'): 0.06060606060606061,\n",
       "             ('sari', 'classes'): 0.5,\n",
       "             ('hugyi', 'aur'): 0.5,\n",
       "             ('gayi', '7:00'): 0.018867924528301886,\n",
       "             ('7:00', 'tk'): 0.2,\n",
       "             ('tk', 'har'): 0.05555555555555555,\n",
       "             ('har', 'pohunchi'): 0.25,\n",
       "             ('pohunchi', 'chai'): 0.5,\n",
       "             ('chai', 'bana'): 0.037037037037037035,\n",
       "             ('bana', 'kr'): 0.1,\n",
       "             ('kr', 'pi'): 0.016129032258064516,\n",
       "             ('sath', 'cnet'): 0.009708737864077669,\n",
       "             ('cnet', 'ki'): 0.5555555555555556,\n",
       "             ('ki', 'assignment'): 0.015267175572519083,\n",
       "             ...})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for bigram in bigrams:\n",
    "#     bigram_probs = bigram_count[bigram] / token_count[bigram[0]]\n",
    "#     # print(bigram, bigram_probs)\n",
    "\n",
    "# for trigram in trigrams:\n",
    "#     trigram_probs = trigram_count[trigram] / bigram_count[trigram[:2]]\n",
    "#     # print(trigram, trigram[:2], trigram_probs)\n",
    "\n",
    "total_tokens = sum(token_count.values())\n",
    "unigram_probs = {token: count / total_tokens for token, count in token_count.items()}\n",
    "\n",
    "bigram_probs = defaultdict()\n",
    "for bigram in bigrams:\n",
    "    bigram_probs[bigram] = bigram_count[bigram] / token_count[bigram[0]]\n",
    "\n",
    "trigram_probs = defaultdict()\n",
    "for trigram in trigrams:\n",
    "    if bigram_count[trigram[:2]] > 0:  \n",
    "        trigram_probs[trigram] = trigram_count[trigram] / bigram_count[trigram[:2]]\n",
    "bigram_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542c57c-67f5-4c74-b43f-79eac1c64ce7",
   "metadata": {},
   "source": [
    "# Generating Diary Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44461204-1853-41ef-ad93-c0aabedd32d9",
   "metadata": {},
   "source": [
    "# Base Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fed438-f65a-4830-a7f5-eaa82da2499a",
   "metadata": {},
   "source": [
    "## Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "04c4348c-898d-4843-b816-7edda2902344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dair ki doston celebrate thi hue class hue.\n",
      "Hue walk or phir jo attend paarh hai baje ki dekha liye.\n",
      "Liye hamien karne gya khaya mein lekin.\n",
      "Lekin markaz cafe break class mai mehmaan lekin deer.\n"
     ]
    }
   ],
   "source": [
    "#weighted random\n",
    "words, probs = list(unigram_probs.keys()), list(unigram_probs.values())  \n",
    "prev_word = None  #store last word of prev sent\n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_word and prev_word in words:  \n",
    "        sentence = [prev_word]  #start with the last word of the previous sentence\n",
    "        sent_len -= 1  \n",
    "    else:\n",
    "        sentence = [random.choices(words, weights=probs)[0]]  #start fresh if no valid transition\n",
    "\n",
    "    sentence += random.choices(words, weights=probs, k=sent_len)  \n",
    "    prev_word = sentence[-1]  #store the last word for the next sentence transition\n",
    "    \n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fee97ac2-583f-4f77-ae4e-20ba080bb19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aur aur aur aur aur aur aur aur aur.\n",
      "Aur aur aur aur aur aur aur aur aur aur aur aur.\n",
      "Aur aur aur aur aur aur aur.\n",
      "Aur aur aur aur aur aur aur aur.\n"
     ]
    }
   ],
   "source": [
    "# max\n",
    "words, probs = list(unigram_probs.keys()), list(unigram_probs.values())  \n",
    "prev_word = None \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_word and prev_word in words:  \n",
    "        sentence = [prev_word]  #start with the last word of the previous sentence\n",
    "        sent_len -= 1  \n",
    "    else:\n",
    "        sentence = [max(unigram_probs, key=unigram_probs.get)]  #start fresh with the most freq unigram\n",
    "        # sentence = [random.choices(words, weights=probs)[0]]  #start fresh if no valid transition\n",
    "        \n",
    "    sentence += [max(unigram_probs, key=unigram_probs.get) for _ in range(sent_len)]  # fill sentence with most probable words\n",
    "    prev_word = sentence[-1] \n",
    "\n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4356de-95b0-4c0e-843a-fecdf141b748",
   "metadata": {},
   "source": [
    "## Bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c5c705a2-4121-49b9-87cf-f4d351069846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3:00 baje pehle ek aur ek option.\n",
      "Jo fast university 10:10 tak phir hamne asr.\n",
      "Khatam tha koi kaam nai gaya agli class.\n",
      "Kaafi acha uthne ki waja sy bohat sy bohat sy kam kar.\n",
      "Bank ja na nlp ke teacher ne apnay bhai.\n"
     ]
    }
   ],
   "source": [
    "# random\n",
    "prev_word = None  \n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_word:  \n",
    "        #find possible next words using bigrams\n",
    "        next_words = [b[1] for b in bigram_probs if b[0] == prev_word]\n",
    "        start_word = random.choice(next_words) if next_words else random.choice(list(unigram_probs.keys()))  \n",
    "    else:\n",
    "        start_word = random.choice(list(unigram_probs.keys()))  #first sentence starts randomly\n",
    "\n",
    "    sentence = [start_word]\n",
    "\n",
    "    for _ in range(sent_len - 1):\n",
    "        prev_word = sentence[-1]\n",
    "        next_words = [b[1] for b in bigram_probs if b[0] == prev_word]\n",
    "\n",
    "        if next_words:\n",
    "            sentence.append(random.choice(next_words))  #randomly choose next word from bigrams\n",
    "        else:\n",
    "            break  #stop sentence if no valid bigram found\n",
    "\n",
    "    prev_word = sentence[-1]  #store last word for next sent transition\n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "537bd5b0-de7c-46d9-b124-fe912a1813a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bjhey uthna para aur phir hum ne khana khaya.\n",
      "Aur phir hum ne khana khaya aur.\n",
      "Phir hum ne khana khaya aur phir hum ne khana khaya aur.\n",
      "Phir hum ne khana khaya aur phir hum ne khana khaya.\n",
      "Aur phir hum ne khana khaya aur phir hum ne khana.\n"
     ]
    }
   ],
   "source": [
    "#max\n",
    "prev_word = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_word:  \n",
    "        #find possible next words with probabilities\n",
    "        next_words = [(b[1], bigram_probs[b]) for b in bigram_probs if b[0] == prev_word]\n",
    "        start_word = max(next_words, key=lambda x: x[1])[0] if next_words else max(unigram_probs, key=unigram_probs.get)  \n",
    "    else:\n",
    "        start_word = max([(b[0], bigram_probs[b]) for b in bigram_probs], key=lambda x: x[1])[0]  \n",
    "\n",
    "    sentence = [start_word]\n",
    "\n",
    "    for _ in range(sent_len - 1):\n",
    "        prev_word = sentence[-1]\n",
    "        next_words = [(b[1], bigram_probs[b]) for b in bigram_probs if b[0] == prev_word]\n",
    "\n",
    "        if next_words:\n",
    "            sentence.append(max(next_words, key=lambda x: x[1])[0])  #pick most probable next word\n",
    "        else:\n",
    "            break  #stop sentence if no valid bigram found\n",
    "\n",
    "    prev_word = sentence[-1]  #store last word for next sent transition\n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79b7e715-596d-41c3-863c-2f3327021662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udhar 3 ghantay free hukr university ka kaam kiya aur.\n",
      "Ki namaz parhi aur phir hum ne khana khaya aur phir hum.\n",
      "Gaya aur phir hum ne khana khaya aur phir hum ne.\n",
      "Hai aur phir hum ne khana khaya aur phir hum ne.\n"
     ]
    }
   ],
   "source": [
    "# backoff and max\n",
    "num_sentences = random.randint(3, 5)  #random number of sentences\n",
    "sentences = []  #store generated sentences\n",
    "\n",
    "for i in range(num_sentences):\n",
    "    sent_len = random.randint(7, 12)\n",
    "    start_word = random.choice([b[0] for b in bigram_probs])\n",
    "    sentence = [start_word]\n",
    "    \n",
    "    # Generate sentence using bigrams\n",
    "    for _ in range(sent_len - 1):\n",
    "        prev_word = sentence[-1]  #get last word in the sentence\n",
    "    \n",
    "        next_words = []\n",
    "        #find all valid next words\n",
    "        for b in bigram_probs:\n",
    "            # print(b, b[0])\n",
    "            if b[0] == prev_word:\n",
    "               next_words.append((b[1], bigram_probs[b]) )\n",
    "    \n",
    "        if next_words:\n",
    "            #pick the word with the highest probability\n",
    "            next_word = max(next_words, key=lambda x: x[1])[0]\n",
    "            sentence.append(next_word)\n",
    "        else:\n",
    "            # Backoff, choose a word based on unigram probabilities\n",
    "            print(\"Backoff triggered\")\n",
    "            next_word = random.choices(list(unigram_probs.keys()), weights=unigram_probs.values())[0]\n",
    "\n",
    "    \n",
    "    print(\" \".join(sentence).capitalize() +\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f3ba42d-069e-4d0e-870e-531cede9d207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isha ki namaz parhi aur phir hum ne khana.\n",
      "Average hi nahi tha to mai na nashta kiya aur phir.\n",
      "Baad mai na nashta kiya aur phir hum ne khana khaya.\n",
      "Thi to mai na nashta kiya aur phir hum ne khana.\n"
     ]
    }
   ],
   "source": [
    "# fixed interpolation weight, backoff and max\n",
    "lambda_interp = 0.7  # Interpolation weight, controls mix of bigram and unigram probabilities\n",
    "\n",
    "num_sentences = random.randint(3, 5)  # Generate a random number of sentences\n",
    "sentences = []  # List to store generated sentences\n",
    "\n",
    "for i in range(num_sentences):\n",
    "    sent_len = random.randint(7, 12)  # Random sentence length within a given range\n",
    "    start_word = random.choice([b[0] for b in bigram_probs])  # Pick a random starting word from bigrams\n",
    "    sentence = [start_word]  # Initialize sentence with the start word\n",
    "    \n",
    "    for _ in range(sent_len - 1):\n",
    "        prev_word = sentence[-1]  # Get the last word in the sentence\n",
    "        \n",
    "        next_words = []  # List to store candidate next words with their probabilities\n",
    "        \n",
    "        # Find all valid bigram continuations\n",
    "        for b in bigram_probs:\n",
    "            if b[0] == prev_word:\n",
    "                bigram_prob = bigram_probs[b]  \n",
    "                unigram_prob = unigram_probs.get(b[1], 1e-6)  #prob of the word as a unigram with smoothing for unseen words\n",
    "                interpolated_prob = lambda_interp * bigram_prob + (1 - lambda_interp) * unigram_prob  #interpolated prob\n",
    "                \n",
    "                next_words.append((b[1], interpolated_prob))  #store word and its interpolated prb\n",
    "\n",
    "        if next_words:\n",
    "            #select the word with the highest interpolated prob\n",
    "            next_word = max(next_words, key=lambda x: x[1])[0]\n",
    "        else:\n",
    "            #backoff\n",
    "            print(\"Backoff triggered\")\n",
    "            next_word = random.choices(list(unigram_probs.keys()), weights=unigram_probs.values())[0]\n",
    "        \n",
    "        sentence.append(next_word) \n",
    "    \n",
    "    print(\" \".join(sentence).capitalize() + \".\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e85931bc-f68f-450a-b009-716ae8005646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chuti hui tou humm shoor daltay rahay thei.\n",
      "Keh diya tha uth keri sha ki routine likh.\n",
      "Rha 7 bajay wo bas bed se reh.\n",
      "Gaya masjid chala ke kaam niptaye ghar pohanchny k mene thori.\n",
      "Daer kae maine jaldi ready hona tha bus.\n"
     ]
    }
   ],
   "source": [
    "prev_word = None \n",
    "words, probs = list(unigram_probs.keys()), list(unigram_probs.values())  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_word:  \n",
    "        #find possible next words using bigram\n",
    "        next_words = [b[1] for b in bigram_probs if b[0] == prev_word]\n",
    "        start_word = random.choice(next_words) if next_words else random.choices(words, weights=probs)[0]  \n",
    "    else:\n",
    "        start_word = random.choices(words, weights=probs)[0]  #first sentence starts based on unigram probability\n",
    "\n",
    "    sentence = [start_word]\n",
    "\n",
    "    for _ in range(sent_len - 1):\n",
    "        prev_word = sentence[-1]\n",
    "        next_words = [b[1] for b in bigram_probs if b[0] == prev_word]\n",
    "\n",
    "        if next_words:\n",
    "            sentence.append(random.choice(next_words))  #pick randomly from valid bigrams\n",
    "        else:\n",
    "            sentence.append(random.choices(words, weights=probs)[0])  #backoff to unigram probability\n",
    "\n",
    "    prev_word = sentence[-1]  #store last word for next sentence transition\n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d2af9472-ee9f-4105-841d-7a01f22a98a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ki kiunke aaj mai khana khaya aur mun dhoye.\n",
      "Aur uske bd meri mama kay nikalnay tak classes huti.\n",
      "Hain university k sath wo hua to doston.\n",
      "Ka workload bhi dhoond liya thodi dair library ja raha.\n",
      "Tha suba 6 bajay tak masjid mein khaya thory ghr wlon.\n"
     ]
    }
   ],
   "source": [
    "# fixed interpolation weight, backoff and random\n",
    "lambda_bigram = 0.7  #weight for bigram\n",
    "lambda_unigram = 1 - lambda_bigram  #weight for unigram\n",
    "prev_word = None  \n",
    "words, probs = list(unigram_probs.keys()), list(unigram_probs.values())  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_word:  \n",
    "        #find possible next words using bigrams\n",
    "        next_words = [(b[1], bigram_probs[b]) for b in bigram_probs if b[0] == prev_word]\n",
    "        if next_words:\n",
    "            start_word = random.choices([w for w, _ in next_words], weights=[p for _, p in next_words])[0]  #random from bigram\n",
    "        else:\n",
    "            start_word = random.choices(words, weights=probs)[0]  #backoff to unigram\n",
    "    else:\n",
    "        #first sentence starts with the most frequent first word in bigrams\n",
    "        # start_word = max([(b[0], bigram_probs[b]) for b in bigram_probs], key=lambda x: x[1])[0]  \n",
    "        start_word = random.choices(words, weights=probs)[0]  #first sentence starts based on unigram probability\n",
    "\n",
    "    sentence = [start_word]\n",
    "\n",
    "    for _ in range(sent_len - 1):\n",
    "        prev_word = sentence[-1]\n",
    "        next_words = [(b[1], bigram_probs[b]) for b in bigram_probs if b[0] == prev_word]\n",
    "\n",
    "        if next_words:\n",
    "            #interpolate bigram and unigram probabilities\n",
    "            words_list, probs_list = zip(*next_words)  \n",
    "            bigram_probs_norm = [p / sum(probs_list) for p in probs_list]  #normalize bigram probs\n",
    "            unigram_probs_norm = [unigram_probs[w] / sum(probs) for w in words_list]  #normalize unigram probs\n",
    "\n",
    "            #combine using fixed lambda\n",
    "            final_probs = [(lambda_bigram * bp) + (lambda_unigram * up) for bp, up in zip(bigram_probs_norm, unigram_probs_norm)]\n",
    "            sentence.append(random.choices(words_list, weights=final_probs)[0])  #sample from interpolated probs\n",
    "        else:\n",
    "            sentence.append(random.choices(words, weights=probs)[0])  #backoff to unigram\n",
    "\n",
    "    prev_word = sentence[-1]  #store last word for next sentence transition\n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d405c301-f270-4d58-a149-30e2fbec0e23",
   "metadata": {},
   "source": [
    "## Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e7fdc662-bad9-412a-a9c7-7b4663bfcfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ki dost jo apnay ghar kashmir gayi hui thi.\n",
      "Hui thi tou mere ghar walo ne mughe.\n",
      "Ne mughe wish kea online tohfay bhi bhejay packing mukamal.\n"
     ]
    }
   ],
   "source": [
    "# random\n",
    "prev_bigram = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_bigram:  \n",
    "        next_words = [(t[2], trigram_probs[t]) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "        if next_words:\n",
    "            words, probs = zip(*next_words)\n",
    "            start_word = random.choices(words, weights=probs)[0]  \n",
    "        else:\n",
    "            start_word = random.choice(list(bigram_probs.keys()))[1]  \n",
    "\n",
    "        sentence = [prev_bigram[0], prev_bigram[1], start_word]  #ensure valid start\n",
    "    else:\n",
    "        start_bigram = random.choice(list(trigram_probs.keys()))[:2]\n",
    "        sentence = [start_bigram[0], start_bigram[1]]  #start with valid bigram\n",
    "\n",
    "    for _ in range(sent_len - len(sentence)):\n",
    "        prev_bigram = tuple(sentence[-2:])\n",
    "        next_words = [(t[2], trigram_probs[t]) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "\n",
    "        if next_words:\n",
    "            words, probs = zip(*next_words)\n",
    "            sentence.append(random.choices(words, weights=probs)[0])  \n",
    "        else:\n",
    "            break  \n",
    "\n",
    "    prev_bigram = tuple(sentence[-2:])  \n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "68edb06e-bcaa-4dae-b6fa-f444264df723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gym gya gym say a ker fresh howa.\n",
      "Fresh howa namz magrib peri or kuch khaya piya 1.\n",
      "Piya 1 ganta aram kiya phir asr ki namaz parhi.\n"
     ]
    }
   ],
   "source": [
    "# max\n",
    "prev_bigram = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_bigram:  \n",
    "        next_words = [(t[2], trigram_probs[t]) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "        start_word = max(next_words, key=lambda x: x[1])[0] if next_words else max(bigram_probs, key=bigram_probs.get)[1]  \n",
    "        sentence = [prev_bigram[0], prev_bigram[1], start_word]  #ensure valid start\n",
    "    else:\n",
    "        # start_bigram = max([(t[:2], trigram_probs[t]) for t in trigram_probs], key=lambda x: x[1])[0]\n",
    "        start_bigram = random.choice(list(trigram_probs.keys()))[:2]        \n",
    "        sentence = [start_bigram[0], start_bigram[1]]  #start with valid bigram\n",
    "\n",
    "    for _ in range(sent_len - len(sentence)):\n",
    "        prev_bigram = tuple(sentence[-2:])\n",
    "        next_words = [(t[2], trigram_probs[t]) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "\n",
    "        if next_words:\n",
    "            next_word = max(next_words, key=lambda x: x[1])[0]\n",
    "            if next_word == prev_bigram[1]:  #prevent infinite loops\n",
    "                break  \n",
    "            sentence.append(next_word)\n",
    "        else:\n",
    "            break  \n",
    "\n",
    "    prev_bigram = tuple(sentence[-2:])  #store last bigram for transition\n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f007c7c1-af71-4f71-b29c-cb26e11eb6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaj koi naya recipe try ki jo din.\n",
      "Jo din ki tayari ki ab ham agla 3 ghantay free tha.\n",
      "Free tha tou mujhay khud nashta banana pada.\n",
      "Banana pada chota bhai ko bhi school drop kerna tha tou mujhay.\n"
     ]
    }
   ],
   "source": [
    "# max + backoff\n",
    "prev_bigram = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_bigram:  \n",
    "        next_words = [(t[2], trigram_probs[t]) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "        start_word = max(next_words, key=lambda x: x[1])[0] if next_words else max(bigram_probs, key=bigram_probs.get)[1]  \n",
    "        sentence = [prev_bigram[0], prev_bigram[1], start_word]  \n",
    "    else:\n",
    "        # start_bigram = max([(t[:2], trigram_probs[t]) for t in trigram_probs], key=lambda x: x[1])[0]\n",
    "        start_bigram = random.choice(list(trigram_probs.keys()))[:2]        \n",
    "        sentence = [start_bigram[0], start_bigram[1]]  \n",
    "\n",
    "    for _ in range(sent_len - len(sentence)):\n",
    "        prev_bigram = tuple(sentence[-2:])\n",
    "        next_words = [(t[2], trigram_probs[t]) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "\n",
    "        if next_words:\n",
    "            sentence.append(max(next_words, key=lambda x: x[1])[0])  \n",
    "        else:\n",
    "            next_bigrams = [(b[1], bigram_probs[b]) for b in bigram_probs if b[0] == prev_bigram[1]]\n",
    "            if next_bigrams:\n",
    "                sentence.append(max(next_bigrams, key=lambda x: x[1])[0])  \n",
    "            else:\n",
    "                sentence.append(max(unigram_probs, key=unigram_probs.get))  \n",
    "\n",
    "    prev_bigram = tuple(sentence[-2:])  \n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "86ff0238-3187-41a2-a0b6-34ed64908c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaafi dusty ho gaye meri pehli class.\n",
      "Pehli class kaafi interesting thi lecture dhyan se suna important.\n",
      "Suna important points note kiye aur phir so.\n",
      "Phir so gya phir 10 am per dubara utha or mu hath.\n",
      "Mu hath dho kar nashta kiya aur phir.\n"
     ]
    }
   ],
   "source": [
    "# fixed lambda interpolation , backoff , max\n",
    "lambda3, lambda2, lambda1 = 0.7, 0.2, 0.1  \n",
    "\n",
    "prev_bigram = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_bigram:  \n",
    "        next_words = [(t[2], trigram_probs[t] * lambda3) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "        start_word = max(next_words, key=lambda x: x[1])[0] if next_words else max(bigram_probs, key=bigram_probs.get)[1]  \n",
    "        sentence = [prev_bigram[0], prev_bigram[1], start_word]  \n",
    "    else:\n",
    "        # start_bigram = max([(t[:2], trigram_probs[t]) for t in trigram_probs], key=lambda x: x[1])[0]\n",
    "        start_bigram = random.choice(list(trigram_probs.keys()))[:2]\n",
    "        sentence = [start_bigram[0], start_bigram[1]]  \n",
    "\n",
    "    for _ in range(sent_len - len(sentence)):\n",
    "        prev_bigram = tuple(sentence[-2:])\n",
    "        next_words = [(t[2], trigram_probs[t] * lambda3) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "\n",
    "        if next_words:\n",
    "            next_word = max(next_words, key=lambda x: x[1])[0]\n",
    "        else:\n",
    "            next_bigrams = [(b[1], bigram_probs[b] * lambda2) for b in bigram_probs if b[0] == prev_bigram[1]]\n",
    "            if next_bigrams:\n",
    "                next_word = max(next_bigrams, key=lambda x: x[1])[0]\n",
    "            else:\n",
    "                next_word = max(unigram_probs, key=lambda k: unigram_probs[k] * lambda1)\n",
    "\n",
    "        sentence.append(next_word)\n",
    "\n",
    "    prev_bigram = tuple(sentence[-2:])  \n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "33395493-31c4-4806-9781-bc4aa4b781f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile use kia aur phir nashta karnay neechay chali gayi.\n",
      "Chali gayi baba lahore se aye hoye thay weekend kay liye tayar.\n",
      "Liye tayar ho kar ami k sath jummah.\n",
      "Sath jummah ki namaz ada ki or submit karvai is k baad.\n",
      "K baad hamne khana khaya aur phir hum ghar ponchy ghar.\n"
     ]
    }
   ],
   "source": [
    "# random + backoff\n",
    "prev_bigram = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_bigram:  \n",
    "        next_words = [(t[2], trigram_probs[t]) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "        if next_words:\n",
    "            words, probs = zip(*next_words)\n",
    "            start_word = random.choices(words, weights=probs)[0]  \n",
    "        else:\n",
    "            start_word = random.choice(list(bigram_probs.keys()))[1]  \n",
    "\n",
    "        sentence = [prev_bigram[0], prev_bigram[1], start_word]  \n",
    "    else:\n",
    "        start_bigram = random.choice(list(trigram_probs.keys()))[:2]\n",
    "        sentence = [start_bigram[0], start_bigram[1]]  \n",
    "\n",
    "    for _ in range(sent_len - len(sentence)):\n",
    "        prev_bigram = tuple(sentence[-2:])\n",
    "        next_words = [(t[2], trigram_probs[t]) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "\n",
    "        if next_words:\n",
    "            words, probs = zip(*next_words)\n",
    "            next_word = random.choices(words, weights=probs)[0]  \n",
    "        else:\n",
    "            next_bigrams = [(b[1], bigram_probs[b]) for b in bigram_probs if b[0] == prev_bigram[1]]\n",
    "            if next_bigrams:\n",
    "                words, probs = zip(*next_bigrams)\n",
    "                next_word = random.choices(words, weights=probs)[0]  \n",
    "            else:\n",
    "                next_word = random.choices(list(unigram_probs.keys()), weights=unigram_probs.values())[0]  \n",
    "\n",
    "        sentence.append(next_word)\n",
    "\n",
    "    prev_bigram = tuple(sentence[-2:])  \n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1256c893-b9be-4de9-8eb3-555220ae6460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tha isliye aram se uthi aur university chal diya wahan.\n",
      "Diya wahan ja kr nascon room kay pass rkha uskay.\n",
      "Rkha uskay bad humnay bohot si batain ki khana khaya.\n",
      "Khana khaya aik dost ne poster design karne ke baad.\n",
      "Ke baad kuch deyr phone istemaal kiya aur 8:30 wali.\n"
     ]
    }
   ],
   "source": [
    "# fixed lambda interpolation, backoff, random\n",
    "lambda3, lambda2, lambda1 = 0.7, 0.2, 0.1  \n",
    "\n",
    "prev_bigram = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_bigram:  \n",
    "        next_words = [(t[2], trigram_probs[t] * lambda3) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "        if next_words:\n",
    "            words, probs = zip(*next_words)\n",
    "            start_word = random.choices(words, weights=probs)[0]  \n",
    "        else:\n",
    "            start_word = random.choice(list(bigram_probs.keys()))[1]  \n",
    "\n",
    "        sentence = [prev_bigram[0], prev_bigram[1], start_word]  \n",
    "    else:\n",
    "        start_bigram = random.choice(list(trigram_probs.keys()))[:2]\n",
    "        sentence = [start_bigram[0], start_bigram[1]]  \n",
    "\n",
    "    for _ in range(sent_len - len(sentence)):\n",
    "        prev_bigram = tuple(sentence[-2:])\n",
    "        next_words = [(t[2], trigram_probs[t] * lambda3) for t in trigram_probs if t[:2] == prev_bigram]\n",
    "\n",
    "        if next_words:\n",
    "            words, probs = zip(*next_words)\n",
    "            next_word = random.choices(words, weights=probs)[0]  \n",
    "        else:\n",
    "            next_bigrams = [(b[1], bigram_probs[b] * lambda2) for b in bigram_probs if b[0] == prev_bigram[1]]\n",
    "            if next_bigrams:\n",
    "                words, probs = zip(*next_bigrams)\n",
    "                next_word = random.choices(words, weights=probs)[0]  \n",
    "            else:\n",
    "                words, probs = zip(*unigram_probs.items())\n",
    "                next_word = random.choices(words, weights=[p * lambda1 for p in probs])[0]  \n",
    "\n",
    "        sentence.append(next_word)\n",
    "\n",
    "    prev_bigram = tuple(sentence[-2:])  \n",
    "    print(\" \".join(sentence).capitalize() + \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3ddc9-5eb3-4278-beb6-a94efe02774f",
   "metadata": {},
   "source": [
    "# Backward Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3caba6d1-46c2-46b4-84d9-a5213783a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jagah dhoond liya 9:30 tk hm sb cousins ikatay huway aur.\n",
      "Waja s khelne tio me taqrebban 4.\n",
      "Prhai kee phir usskay baad hamen namaz miss hogyi jiski.\n",
      "Kee phir thoridere prhai kee phir thoridere prhai kee phir thoridere.\n",
      "Phir thoridere prhai kee phir thoridere prhai.\n"
     ]
    }
   ],
   "source": [
    "# max\n",
    "prev_word = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_word:  \n",
    "        #find possible previous words based on the second word of the bigram\n",
    "        prev_words = [(b[0], bigram_probs[b]) for b in bigram_probs if b[1] == prev_word]\n",
    "        start_word = max(prev_words, key=lambda x: x[1])[0] if prev_words else max(unigram_probs, key=unigram_probs.get)  \n",
    "    else:\n",
    "        #first sentence starts with most frequent word\n",
    "        start_word = max(unigram_probs, key=unigram_probs.get)  \n",
    "\n",
    "    sentence = [start_word]  \n",
    "\n",
    "    for _ in range(sent_len - 1):\n",
    "        prev_word = sentence[-1]\n",
    "        prev_words = [(b[0], bigram_probs[b]) for b in bigram_probs if b[1] == prev_word]\n",
    "\n",
    "        if prev_words:\n",
    "            sentence.append(max(prev_words, key=lambda x: x[1])[0])  #pick most probable previous word\n",
    "        else:\n",
    "            break  #stop if no valid bigram is found  \n",
    "\n",
    "    prev_word = sentence[-1]  #store last word for next sentence transition\n",
    "    print(\" \".join(reversed(sentence)).capitalize() + \".\")  #reverse before printing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a92a8adf-9ba9-427d-a1c5-72a2310a5082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dekha laptop khola proposal submit karvai is dauraan thoda pending assignments start.\n",
      "Hamra samaan unpack kea online thori daer kae maine juch dair tv.\n",
      "Se bezti hui uske baad mainy thori sardi bhi.\n",
      "Gy qk aj mera alaaka meh coffee achay.\n",
      "Khola proposal submit karvai is dauraan thoda hawa lene pohonch.\n"
     ]
    }
   ],
   "source": [
    "#random\n",
    "prev_word = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    if prev_word:  \n",
    "        prev_words = [(b[0], bigram_probs[b]) for b in bigram_probs if b[1] == prev_word]\n",
    "        if prev_words:\n",
    "            words, probs = zip(*prev_words)\n",
    "            start_word = random.choices(words, weights=probs)[0]  \n",
    "        else:\n",
    "            start_word = random.choices(list(unigram_probs.keys()), weights=unigram_probs.values())[0]  \n",
    "    else:\n",
    "        start_word = random.choices(list(unigram_probs.keys()), weights=unigram_probs.values())[0]  \n",
    "\n",
    "    sentence = [start_word]  \n",
    "\n",
    "    for _ in range(sent_len - 1):\n",
    "        prev_word = sentence[-1]\n",
    "        prev_words = [(b[0], bigram_probs[b]) for b in bigram_probs if b[1] == prev_word]\n",
    "\n",
    "        if prev_words:\n",
    "            words, probs = zip(*prev_words)\n",
    "            sentence.append(random.choices(words, weights=probs)[0])  \n",
    "        else:\n",
    "            break  \n",
    "\n",
    "    prev_word = sentence[-1]  \n",
    "    print(\" \".join(reversed(sentence)).capitalize() + \".\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7d429-4fc8-45da-bdd0-23bf6d5b0075",
   "metadata": {},
   "source": [
    "# Bidirectional Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7c725b8f-3917-40b4-be1d-0addf8b7e289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hm sb cousins ikatay huway aur phir hum ne khana khaya.\n",
      "Cousins ikatay huway aur phir hum ne.\n",
      "Sb cousins ikatay huway aur phir hum ne khana.\n",
      "Hm sb cousins ikatay huway aur phir hum ne khana khaya.\n"
     ]
    }
   ],
   "source": [
    "#max\n",
    "prev_word = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    #pick the most frequent unigram as the starting word\n",
    "    start_word = max(unigram_probs, key=unigram_probs.get)  \n",
    "    sentence_forward = [start_word]  \n",
    "    sentence_backward = [start_word]  \n",
    "\n",
    "    #generate forward sentence (left to right)\n",
    "    for _ in range(sent_len // 2):\n",
    "        prev_word = sentence_forward[-1]\n",
    "        next_words = [(b[1], bigram_probs[b]) for b in bigram_probs if b[0] == prev_word]\n",
    "\n",
    "        if next_words:\n",
    "            sentence_forward.append(max(next_words, key=lambda x: x[1])[0])  \n",
    "        else:\n",
    "            break  \n",
    "\n",
    "    #generate backward sentence (right to left)\n",
    "    for _ in range(sent_len // 2):\n",
    "        next_word = sentence_backward[0]  \n",
    "        prev_words = [(b[0], bigram_probs[b]) for b in bigram_probs if b[1] == next_word]\n",
    "\n",
    "        if prev_words:\n",
    "            sentence_backward.insert(0, max(prev_words, key=lambda x: x[1])[0])  \n",
    "        else:\n",
    "            break  \n",
    "\n",
    "    #merge backward and forward sentences\n",
    "    full_sentence = sentence_backward[:-1] + sentence_forward  \n",
    "    print(\" \".join(full_sentence).capitalize() + \".\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "76f3ab92-ef96-4cc3-a0ee-59a37e4a0e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesri alarm baji or bohat kuch khanay.\n",
      "Upcoming exams ki chuhti thi to ham ne biryani thi ke.\n",
      "Pehle agle hafte ka islye dobara neend aa k liye nikala wapis akr.\n"
     ]
    }
   ],
   "source": [
    "# random\n",
    "#this generates sentences using both left-to-right and right-to-left bigram models with random selection\n",
    "prev_word = None  \n",
    "\n",
    "for _ in range(random.randint(3, 5)):  \n",
    "    sent_len = random.randint(7, 12)  \n",
    "\n",
    "    #pick a random starting word based on unigram probabilities\n",
    "    start_word = random.choices(list(unigram_probs.keys()), weights=unigram_probs.values())[0]  \n",
    "    sentence_forward = [start_word]  \n",
    "    sentence_backward = [start_word]  \n",
    "\n",
    "    #generate forward sentence (left to right)\n",
    "    for _ in range(sent_len // 2):\n",
    "        prev_word = sentence_forward[-1]\n",
    "        next_words = [(b[1], bigram_probs[b]) for b in bigram_probs if b[0] == prev_word]\n",
    "\n",
    "        if next_words:\n",
    "            words, probs = zip(*next_words)\n",
    "            sentence_forward.append(random.choices(words, weights=probs)[0])  \n",
    "        else:\n",
    "            break  \n",
    "\n",
    "    #generate backward sentence (right to left)\n",
    "    for _ in range(sent_len // 2):\n",
    "        next_word = sentence_backward[0]  \n",
    "        prev_words = [(b[0], bigram_probs[b]) for b in bigram_probs if b[1] == next_word]\n",
    "\n",
    "        if prev_words:\n",
    "            words, probs = zip(*prev_words)\n",
    "            sentence_backward.insert(0, random.choices(words, weights=probs)[0])  \n",
    "        else:\n",
    "            break  \n",
    "\n",
    "    #merge backward and forward sentences\n",
    "    full_sentence = sentence_backward[:-1] + sentence_forward  \n",
    "    print(\" \".join(full_sentence).capitalize() + \".\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59004ccf-3b30-4f4d-9465-8947d6057062",
   "metadata": {},
   "source": [
    "# Evaluating Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc0529-4e83-4eb7-91df-ca474be1e0bb",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6923285-1202-4a56-8960-2d07827e6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Perplexity: 5917.763161660183\n",
      "Bigram Perplexity: 1266.3712776217656\n",
      "Trigram Perplexity: 861.7606020242736\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#tokenize test data\n",
    "test_tokens = list(word_tokenize(test))\n",
    "\n",
    "#unigram perplexity\n",
    "def calculate_unigram_perplexity(test_tokens, unigram_probs):\n",
    "    log_prob = 0\n",
    "    N = len(test_tokens)\n",
    "\n",
    "    for word in test_tokens:\n",
    "        prob = unigram_probs.get(word, 1e-10)  #small value for unseen words\n",
    "        log_prob += math.log(prob)\n",
    "    \n",
    "    return math.exp(-log_prob / N)\n",
    "\n",
    "#bigram perplexity\n",
    "def calculate_bigram_perplexity(test_tokens, bigram_probs, unigram_probs):\n",
    "    log_prob = 0\n",
    "    N = len(test_tokens)\n",
    "\n",
    "    for i in range(1, N):\n",
    "        bigram = (test_tokens[i-1], test_tokens[i])\n",
    "        prob = bigram_probs.get(bigram, unigram_probs.get(test_tokens[i], 1e-10))  #backoff to unigram\n",
    "        log_prob += math.log(prob)\n",
    "\n",
    "    return math.exp(-log_prob / N)\n",
    "\n",
    "#trigram perplexity\n",
    "def calculate_trigram_perplexity(test_tokens, trigram_probs, bigram_probs, unigram_probs):\n",
    "    log_prob = 0\n",
    "    N = len(test_tokens)\n",
    "\n",
    "    for i in range(2, N):\n",
    "        trigram = (test_tokens[i-2], test_tokens[i-1], test_tokens[i])\n",
    "        bigram = (test_tokens[i-1], test_tokens[i])\n",
    "        unigram = test_tokens[i]\n",
    "\n",
    "        if trigram in trigram_probs:\n",
    "            prob = trigram_probs[trigram]\n",
    "        elif bigram in bigram_probs:\n",
    "            prob = bigram_probs[bigram]  #backoff to bigram\n",
    "        else:\n",
    "            prob = unigram_probs.get(unigram, 1e-10)  #backoff to unigram\n",
    "        \n",
    "        log_prob += math.log(prob)\n",
    "\n",
    "    return math.exp(-log_prob / N)\n",
    "\n",
    "#calculate perplexities\n",
    "unigram_pp = calculate_unigram_perplexity(test_tokens, unigram_probs)\n",
    "bigram_pp = calculate_bigram_perplexity(test_tokens, bigram_probs, unigram_probs)\n",
    "trigram_pp = calculate_trigram_perplexity(test_tokens, trigram_probs, bigram_probs, unigram_probs)\n",
    "\n",
    "print(f\"Unigram Perplexity: {unigram_pp}\")\n",
    "print(f\"Bigram Perplexity: {bigram_pp}\")\n",
    "print(f\"Trigram Perplexity: {trigram_pp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47865df5-d07b-4cc0-a492-d4e4bfa64d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
